{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Input Pipeline\n",
    "\n",
    "Link to the Youtube video tutorial: https://www.youtube.com/watch?v=VFEOskzhhbc&list=PLeo1K3hjS3uu7CxAacxVndI4bE_o3BDtO&index=44\n",
    "\n",
    "1) **Motivation of using Tensorflow input pipeline:**\n",
    "    1) <img src=\"hidden\\photo1.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 400px;\"/>  <br />\n",
    "        1) Let's say you are building your typical cats and dogs image classification model. These images are obviously stored on hard disk and you need to load these images into RAM into some kind of numpy array or pandas data frame. You have to convert these images into numbers because machine learning model understand numbers they don't understand images. So now you have loaded them into lesson Numpy x train y train and you give it to your model for training things are looking fine when you have thousand images\n",
    "\n",
    "    2) <img src=\"hidden\\photo2.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 400px;\"/>  <br />\n",
    "        1) what if you have 10 million images in in deep learning environment, you know typically you have a lot of data. When you're running this on your computer which has only 8 gigabyte of RAM, when you try to load it you know what your computer is going to tell you? It will be like too much data buddy, I cannot handle it! please help me! \n",
    "\n",
    "    3) <img src=\"hidden\\photo3.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 400px;\"/>  <br />\n",
    "        1) Alright so one approach of tackling this issue is how about we load these images into batches this is called a streaming approach. So batch 1 is thousand images, you load this into some kind of special data structures (by the way this table is not your Numpy array or pandas data frame, it is some kind of special data structure and we'll talk about what that data structure is). You load thousand images so you give batch 1 for your model training. Then you do batch 2, batch 3, batch 4 and so on. And things work perfectly. So now you'll ask me what is that special data structure? well that special data structure is tf.data.Dataset, and this is what helps you build your Tensorflow input pipeline. In order to build Tensorflow input pipeline, you need to use tf.data API framework and tf.data.Dataset is the main class in this framework.\n",
    "\n",
    "    4) <img src=\"hidden\\photo4.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 400px;\"/>  <br />\n",
    "        1) All right, what if I have some blurry images? I don't want to directly load the images and do my model training because you all know we have to do data cleaning & data transformation such as scaling, things like that. tf.data.Dataset fortunately has a lot of good API to support the transformation. So for example here, the red row is that blurry image and you can use filter function. You can say .filter() and this .filter() is a custom function defined by you, where you will detect if the image is blurry or not. We are not going to go into details on how exactly you detect the blurry image, but you get the point you can have a custom filter function which you can supply to tf.data.Dataset and it will filter it out. You see the red row is gone now in this particular instance of this data structure and then you can do model training.\n",
    "\n",
    "    5) <img src=\"hidden\\photo5.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 400px;\"/>  <br />\n",
    "        1) You might want to do more transformation where you all know typically when you are training your image dataset, you want to scale it. So all these values by the way that you're seeing I don't know if you noticed but there are three dimensional arrays. You know RGB, so an image is presented by RGB channels and these values are from 0 to 255 and it's a usual practice that we scale this by dividing it by 255. So now, you can do .map() and then define a lambda function, if you are aware about python lambda function it's a simple function which will do x divided by 255 on each of these values, so you can see that 34 divided by 255 is 0.13... Alright, and then you can do your model training. So overall you can use tf.data.Dataset to do filtering, mapping, shuffling and lot of different transformations now.\n",
    "\n",
    "    6) <img src=\"hidden\\photo6.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 400px;\"/>  <br />\n",
    "        1) What if I can write all this transformation in a single line of code? This is how it looks. This is a single line of code that forming your complete data input pipeline (Tensorflow input pipeline). So the first step, list image list files that will load the images from your hard disk into memory. Then you do .map() so .map() is like you know pandas .apply() where you want to run some transformation on your images. So I have just loaded these images from hard disk I would probably want to convert it into Numpy array and then do some transformation. By the way, Numpy array is internally it's inside your tf data set so tf.data.Dataset is kind of you know providing abstractions over it so you essentially your Numpy array is converted to a tensor you know and the tensor is an underlying data structure for tf.data.Dataset. Now you converted these images into array extracted label from the folder and then the next step would be filtering blurry images. Then you do mapping. So mapping is just your scaling, you know bringing values from zero to one and that is your tf.data.Dataset. So that first step is called building data pipeline. In this pipeline, you perform ETL (extract, transform & load), all kind of transformations. I just showed you few transformation you can do repeat you can do batching you can do so many transformation we'll look at some of those in our coding which is part two of this video but you get an idea that you build a data input pipeline. Then the second step would be training the model where you supply tf_dataset in your model.fit() until now if you've seen my previous videos we would use either Numpy array or Pandas data frame as an input of fit function but now we'll be using tf_dataset.\n",
    "\n",
    "    7) <img src=\"hidden\\photo7.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 400px;\"/>  <br />\n",
    "        1) You can load text files or spreadsheet. It's not just images. You can load any kind of data. You can load images from cloud, it doesn't have to be your local hard disk, and you can use this data input pipeline for doing batch loading, shuffling, filtering mapping and all of this is called ETL (extract, transform, & load). In the end, what you get is your tf_dataset which you can directly feed into your tensorflow model.\n",
    "\n",
    "    8) <img src=\"hidden\\photo8.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 400px;\"/>  <br />\n",
    "        1) Just to summarize, the tensorflow input pipeline offers two big benefits. The first benefit is you can handle huge dataset easily by streaming them from either disk or any other cloud storage. The second benefit is you can apply various type of transformation which you typically need to train your deep learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a tf_dataset (whose samples are numbers)\n",
    "\n",
    "In this tutorial, tf_dataset is a tensor object created using tensorflow API (tf.data.Dataset.from_tensor_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>\n"
     ]
    }
   ],
   "source": [
    "# The daily_sales_numbers is the dataset in this tutorial. The daily_sales_numbers stores 21 thousand dollars, 22 thousand dollars,.... and vice versa. However, the negative value in daily_sales_numbers are the error datas (because daily sales numbers cannot be negative values).\n",
    "daily_sales_numbers = [21, 22, -108, 31, -1, 32, 34, 31]\n",
    "\n",
    "# Create a tf dataset (tensor object) called tf_dataset, from a python list\n",
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales_numbers)\n",
    "print(tf_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform different operations on a dataset separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods to access the elements in the tf_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print the elements in tf_dataset as tensor object:\n",
      "tf.Tensor(21, shape=(), dtype=int32)\n",
      "tf.Tensor(22, shape=(), dtype=int32)\n",
      "tf.Tensor(-108, shape=(), dtype=int32)\n",
      "tf.Tensor(31, shape=(), dtype=int32)\n",
      "tf.Tensor(-1, shape=(), dtype=int32)\n",
      "tf.Tensor(32, shape=(), dtype=int32)\n",
      "tf.Tensor(34, shape=(), dtype=int32)\n",
      "tf.Tensor(31, shape=(), dtype=int32)\n",
      "\n",
      "Print the elements in tf_dataset as numpy object (Convert each tensor object into numpy array using numpy()):\n",
      "21\n",
      "22\n",
      "-108\n",
      "31\n",
      "-1\n",
      "32\n",
      "34\n",
      "31\n",
      "\n",
      "Print the elements in tf_dataset as numpy object (Convert each tensor object into numpy array using as_numpy_iterator()):\n",
      "21\n",
      "22\n",
      "-108\n",
      "31\n",
      "-1\n",
      "32\n",
      "34\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "print('Print the elements in tf_dataset as tensor object:')\n",
    "for sales in tf_dataset:\n",
    "    print(sales) # Each element in the tf_dataset is a tensor object\n",
    " \n",
    "print('\\nPrint the elements in tf_dataset as numpy object (Convert each tensor object into numpy array using numpy()):')\n",
    "for sales in tf_dataset:\n",
    "    print(sales.numpy()) # Convert each element in the tf_dataset from a tensor object into numpy object, using numpy()\n",
    "\n",
    "print('\\nPrint the elements in tf_dataset as numpy object (Convert each tensor object into numpy array using as_numpy_iterator()):')\n",
    "for sales in tf_dataset.as_numpy_iterator(): # Convert each element in the tf_dataset from a tensor object into numpy object, using as_numpy_iterator()\n",
    "    print(sales) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Print the first 3 elements in tf_dataset as numpy object (Convert each tensor object into numpy array using numpy()):\n",
      "21\n",
      "22\n",
      "-108\n",
      "\n",
      "Print the elements/samples in tf_dataset_filtered [with error data removed] as numpy object (Convert each tensor object into numpy array using as_numpy_iterator()):\n",
      "21\n",
      "22\n",
      "31\n",
      "32\n",
      "34\n",
      "31\n",
      "\n",
      "Print the elements/samples in tf_dataset_filtered_CurrencyChanged [with error data removed & currency changed] as numpy object (Convert each tensor object into numpy array using as_numpy_iterator()):\n",
      "1512\n",
      "1584\n",
      "2232\n",
      "2304\n",
      "2448\n",
      "2232\n"
     ]
    }
   ],
   "source": [
    "print('\\nPrint the first 3 elements in tf_dataset as numpy object (Convert each tensor object into numpy array using numpy()):')\n",
    "for sales in tf_dataset.take(3): #.take(N) means only get the first N samples of the tf_dataset (means the loop only runs for N iterations). At each iteration, a taken sample will be stored in sales. \n",
    "    print(sales.numpy()) # Convert each element in the tf_dataset from a tensor object into numpy object, using numpy()\n",
    "\n",
    "# Filter/remove the error data in the dataset (In this tutorial, the error data is sample in negative value), by using the self-defined filter function (In this tutorial, the filter function is filter(lambda x: x>0))\n",
    "tf_dataset_filtered = tf_dataset.filter(lambda x: x>0)\n",
    "print('\\nPrint the elements/samples in tf_dataset_filtered [with error data removed] as numpy object (Convert each tensor object into numpy array using as_numpy_iterator()):')\n",
    "for sales in tf_dataset_filtered.as_numpy_iterator():\n",
    "    print(sales)\n",
    "\n",
    "# Convert the currency of each sample from USD into Rupees, with the ratio of 1 USD : 72 Rupees, using the self-defined map function (In this tutorial, the map function is filter(lambda x: x*72))\n",
    "tf_dataset_filtered_CurrencyChanged = tf_dataset_filtered.map(lambda x: x*72)\n",
    "print('\\nPrint the elements/samples in tf_dataset_filtered_CurrencyChanged [with error data removed & currency changed] as numpy object (Convert each tensor object into numpy array using as_numpy_iterator()):')\n",
    "for sales in tf_dataset_filtered_CurrencyChanged.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print the elements/samples in tf_dataset_filtered_CurrencyChanged_shuffled [with error data removed, currency changed, shuffled] as numpy object (Convert each tensor object into numpy array using as_numpy_iterator()):\n",
      "1584\n",
      "2304\n",
      "2448\n",
      "1512\n",
      "2232\n",
      "2232\n"
     ]
    }
   ],
   "source": [
    "# Randomly shuffle the samples in tf_dataset_filtered_CurrencyChanged, using the buffer size of 3. The detail explanation of shuffle buffer size: https://stackoverflow.com/questions/53514495/what-does-batch-repeat-and-shuffle-do-with-tensorflow-dataset\n",
    "tf_dataset_filtered_CurrencyChanged_shuffled = tf_dataset_filtered_CurrencyChanged.shuffle(3)\n",
    "print('Print the elements/samples in tf_dataset_filtered_CurrencyChanged_shuffled [with error data removed, currency changed, shuffled] as numpy object (Convert each tensor object into numpy array using as_numpy_iterator()):')\n",
    "for sales in tf_dataset_filtered_CurrencyChanged_shuffled.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print the elements/samples in tf_dataset_filtered_CurrencyChanged_shuffled_batched [with error data removed, currency changed, shuffled, and batched] as numpy object (Convert each tensor object into numpy array using as_numpy_iterator()):\n",
      "[1584 2304]\n",
      "[2448 2232]\n",
      "[2232 1512]\n"
     ]
    }
   ],
   "source": [
    "# Do batching, by creating batches of size 2 (means each batch will have 2 samples of the dataset)\n",
    "tf_dataset_filtered_CurrencyChanged_shuffled_batched = tf_dataset_filtered_CurrencyChanged_shuffled.batch(2)\n",
    "\n",
    "print('Print the elements/samples in tf_dataset_filtered_CurrencyChanged_shuffled_batched [with error data removed, currency changed, shuffled, and batched] as numpy object (Convert each tensor object into numpy array using as_numpy_iterator()):')\n",
    "for sales_batch in tf_dataset_filtered_CurrencyChanged_shuffled_batched: # Since the dataset called tf_dataset_filtered_CurrencyChanged_shuffled only have 6 samples, by defining each batch will have 2 samples, there will be 3 batches to accomodate all the samples of the dataset.\n",
    "    print(sales_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform different operations on a dataset in one single line (using Tensorflow input pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print the elements/samples in tf_dataset_OperationsInSingleLine [with error data removed, currency changed, shuffled, and batched] as numpy object (Convert each tensor object into numpy array using as_numpy_iterator()):\n",
      "[2232 1512]\n",
      "[1584 2232]\n",
      "[2304 2448]\n"
     ]
    }
   ],
   "source": [
    "# Perform different operations on the same dataset (tf_dataset) in one single line (start with filtering, followed by mapping, shuffling, and ends with batching). In other words, the one single line is called the tensorflow input pipeline.\n",
    "tf_dataset_OperationsInSingleLine = tf_dataset.filter(lambda x: x>0).map(lambda y: y*72).shuffle(3).batch(2)\n",
    "\n",
    "print('Print the elements/samples in tf_dataset_OperationsInSingleLine [with error data removed, currency changed, shuffled, and batched] as numpy object (Convert each tensor object into numpy array using as_numpy_iterator()):')\n",
    "for sales in tf_dataset_OperationsInSingleLine.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a tf_dataset (whose samples are images)\n",
    "\n",
    "The purpose of this tutorial is to give you an idea of tensorflow input pipeline. You will be using that while training tensorflow deep learning models. So here, we are not doing any training, we are just building the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 3 image directories stored in the image_dataset variable:\n",
      "b'deep-learning-keras-tf-tutorial\\\\44_tf_data_pipeline\\\\images\\\\cat\\\\20 Reasons Why Cats Make the Best Pets....jpg'\n",
      "b'deep-learning-keras-tf-tutorial\\\\44_tf_data_pipeline\\\\images\\\\cat\\\\7 Foods Your Cat Can_t Eat.jpg'\n",
      "b'deep-learning-keras-tf-tutorial\\\\44_tf_data_pipeline\\\\images\\\\cat\\\\A cat appears to have caught the....jpg'\n"
     ]
    }
   ],
   "source": [
    "# Load the image dataset by storing the list of the directory of all image files of the dataset in the image_dataset variable, through providing the list as the input of tf.data.dataset.list_files(). Shuffle=False means you don't want to provide the directory of the images in a random sequence. Shuffle=True means you want to provide the directory of the images in a random sequence.\n",
    "images_dataset = tf.data.Dataset.list_files('deep-learning-keras-tf-tutorial/44_tf_data_pipeline/images/*/*', shuffle=False)\n",
    "\n",
    "# Show the first 3 image directories stored in the image_dataset variable\n",
    "print('The first 3 image directories stored in the image_dataset variable:')\n",
    "for file in images_dataset.take(3):\n",
    "    print(file.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The first 3 image directories stored in the image_dataset_shuffled variable:\n",
      "b'deep-learning-keras-tf-tutorial\\\\44_tf_data_pipeline\\\\images\\\\dog\\\\66 gifts for dogs or dog lovers to get_yythk....jpg'\n",
      "b'deep-learning-keras-tf-tutorial\\\\44_tf_data_pipeline\\\\images\\\\dog\\\\How to make your dog feel comfortable....jpg'\n",
      "b'deep-learning-keras-tf-tutorial\\\\44_tf_data_pipeline\\\\images\\\\dog\\\\The 25 Cutest Dog Breeds - Most....jpg'\n"
     ]
    }
   ],
   "source": [
    "# Randomly shuffle the samples/directories in image_dataset variable, using buffer size of 200. So now, image_dataset_shuffled contains the cat and dog image directory in mixed way (means not having all the cat image directories first, only followed by all the dog image directories)\n",
    "image_dataset_shuffled = images_dataset.shuffle(200)\n",
    "print('\\nThe first 3 image directories stored in the image_dataset_shuffled variable:')\n",
    "for file in image_dataset_shuffled.take(3):\n",
    "    print(file.numpy())\n",
    "\n",
    "# , so that the images can be accessed on the disk and read their features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the unique classes (ground truth)\n",
    "class_names = [\"cat\",\"dog\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset consists of 130 images.\n",
      "The train set consists of 104 images.\n",
      "The test set consists of 26 images.\n"
     ]
    }
   ],
   "source": [
    "# Count the number of samples/images in the dataset\n",
    "image_count = len(image_dataset_shuffled)\n",
    "print('The dataset consists of ' + str(image_count) + ' images.')\n",
    "\n",
    "# Set the train set having 80% samples of the dataset\n",
    "train_size = int(image_count*0.8)\n",
    "\n",
    "# Get the first train_size samples in image_dataset_shuffled variable, then store them in the X_train variable\n",
    "train_dataset = image_dataset_shuffled.take(train_size)\n",
    "\n",
    "# Skip the first train_size samples in image_dataset_shuffled variable. Get the (train_size+1)th to last sample in image_dataset_shuffled variable, then store them in the X_test variable\n",
    "test_dataset = image_dataset_shuffled.skip(train_size)\n",
    "\n",
    "print('The train set consists of ' + str(len(train_dataset)) + ' images.')\n",
    "print('The test set consists of ' + str(len(test_dataset)) + ' images.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra: Explain the concept of retrieve the ground truth (label) of an image, based on the image directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 1st image path in the train set:\n",
      " b'deep-learning-keras-tf-tutorial\\\\44_tf_data_pipeline\\\\images\\\\cat\\\\Cat Advice _ Collecting a Urine Sample....jpg'\n",
      "\n",
      "The label of the 1st image in the train set:  tf.Tensor(b'cat', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# For example, take an image directory\n",
    "for file in train_dataset.take(1):\n",
    "    s = file\n",
    "\n",
    "print('The 1st image path in the train set:\\n', s.numpy())\n",
    "\n",
    "import os\n",
    "\n",
    "# Split the directory into words, using the os separator (os.path.sep)\n",
    "label_example = tf.strings.split(s, os.path.sep)[3]\n",
    "print('\\nThe label of the 1st image in the train set: ', label_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the label (ground truth) of all images/samples of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-define a function to retrieve the label (ground truth) of the provided images/samples\n",
    "def get_label(file_path):\n",
    "    return tf.strings.split(file_path, os.path.sep)[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the data (features) of all images/samples of the dataset (Their features are obtained by loading them from laptop's disk into laptop's RAM, then read their numpy array data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-define a function to retrieve the data (features) & label (ground truth) of the provided images/samples simultaneuosly\n",
    "def process_image(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = tf.io.read_file(file_path) # Read the file \n",
    "    img = tf.image.decode_jpeg(img) # Decode the file to get its features. Since the file is a jpeg image. So I need to decode the file using a function called decode_jpeg()\n",
    "    img = tf.image.resize(img, [128, 128]) # Resize the image to the dimension of 128 x 128 pixels \n",
    "    return img, label # Return the feature and label of the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform different operations on a dataset separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve the features & label of each image/file simultaneously\n",
    "\n",
    "A.map(B) means the function B is applied on each elements in variable A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the train set image/file at index  0\n",
      "The features:\n",
      " [[[255. 255. 255.   0.]\n",
      "  [255. 255. 255.   0.]\n",
      "  [255. 255. 255.   0.]\n",
      "  ...\n",
      "  [255. 255. 255.   0.]\n",
      "  [255. 255. 255.   0.]\n",
      "  [255. 255. 255.   0.]]\n",
      "\n",
      " [[255. 255. 255.   0.]\n",
      "  [255. 255. 255.   0.]\n",
      "  [255. 255. 255.   0.]\n",
      "  ...\n",
      "  [255. 255. 255.   0.]\n",
      "  [255. 255. 255.   0.]\n",
      "  [255. 255. 255.   0.]]\n",
      "\n",
      " [[255. 255. 255.   0.]\n",
      "  [255. 255. 255.   0.]\n",
      "  [255. 255. 255.   0.]\n",
      "  ...\n",
      "  [255. 255. 255.   0.]\n",
      "  [255. 255. 255.   0.]\n",
      "  [255. 255. 255.   0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255. 255. 255.   0.]\n",
      "  [255. 255. 255.   0.]\n",
      "  [255. 255. 255.   0.]\n",
      "  ...\n",
      "  [255. 255. 255.   0.]\n",
      "  [255. 255. 255.   0.]\n",
      "  [255. 255. 255.   0.]]\n",
      "\n",
      " [[255. 255. 255.   0.]\n",
      "  [255. 255. 255.   0.]\n",
      "  [255. 255. 255.   0.]\n",
      "  ...\n",
      "  [255. 255. 255.   0.]\n",
      "  [255. 255. 255.   0.]\n",
      "  [255. 255. 255.   0.]]\n",
      "\n",
      " [[255. 255. 255.   0.]\n",
      "  [255. 255. 255.   0.]\n",
      "  [255. 255. 255.   0.]\n",
      "  ...\n",
      "  [255. 255. 255.   0.]\n",
      "  [255. 255. 255.   0.]\n",
      "  [255. 255. 255.   0.]]]\n",
      "The label:\n",
      " b'dog'\n",
      "\n",
      "\n",
      "\n",
      "For the train set image/file at index  1\n",
      "The features:\n",
      " [[[ 26.        26.        14.      ]\n",
      "  [ 29.        29.        17.      ]\n",
      "  [ 31.        31.        19.      ]\n",
      "  ...\n",
      "  [ 33.        31.        18.      ]\n",
      "  [ 38.        35.        18.      ]\n",
      "  [ 43.        38.        18.      ]]\n",
      "\n",
      " [[ 26.        26.        14.      ]\n",
      "  [ 29.        29.        17.      ]\n",
      "  [ 31.        31.        19.      ]\n",
      "  ...\n",
      "  [ 33.        31.        17.84375 ]\n",
      "  [ 39.        36.        17.      ]\n",
      "  [ 44.078125  39.078125  18.921875]]\n",
      "\n",
      " [[ 25.        25.        13.      ]\n",
      "  [ 29.        29.        17.      ]\n",
      "  [ 32.        32.        20.      ]\n",
      "  ...\n",
      "  [ 33.        31.        16.      ]\n",
      "  [ 40.        37.796875  17.203125]\n",
      "  [ 44.        39.        17.      ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[107.        94.        49.      ]\n",
      "  [108.796875  95.796875  50.796875]\n",
      "  [118.       105.        60.      ]\n",
      "  ...\n",
      "  [189.59375  166.59375   90.59375 ]\n",
      "  [185.39062  162.39062   86.390625]\n",
      "  [184.1875   161.1875    85.1875  ]]\n",
      "\n",
      " [[100.234375  89.078125  44.078125]\n",
      "  [104.078125  92.921875  47.921875]\n",
      "  [113.15625  102.        57.      ]\n",
      "  ...\n",
      "  [187.84375  162.07812   87.      ]\n",
      "  [182.92188  157.15625   82.078125]\n",
      "  [181.84375  156.07812   81.      ]]\n",
      "\n",
      " [[ 95.078125  87.71875   43.      ]\n",
      "  [ 98.71875   91.359375  46.640625]\n",
      "  [107.71875  100.359375  55.640625]\n",
      "  ...\n",
      "  [184.       158.        83.      ]\n",
      "  [182.       156.        81.      ]\n",
      "  [175.71875  149.71875   74.71875 ]]]\n",
      "The label:\n",
      " b'dog'\n",
      "\n",
      "\n",
      "\n",
      "For the train set image/file at index  2\n",
      "The features:\n",
      " [[[ 79.70703   87.70703   90.70703 ]\n",
      "  [ 77.52734   83.52734   81.52734 ]\n",
      "  [ 94.20703   96.20703   91.20703 ]\n",
      "  ...\n",
      "  [208.66016  212.66016  211.66016 ]\n",
      "  [225.03906  227.03906  224.03906 ]\n",
      "  [217.22656  218.22656  213.22656 ]]\n",
      "\n",
      " [[ 94.62109  102.62109  104.62109 ]\n",
      "  [ 85.94141   91.94141   89.94141 ]\n",
      "  [ 97.640625 101.62109   95.96094 ]\n",
      "  ...\n",
      "  [219.28125  222.64062  221.64062 ]\n",
      "  [212.80078  214.80078  211.80078 ]\n",
      "  [213.69922  214.3789   210.33984 ]]\n",
      "\n",
      " [[ 97.       103.265625 103.53125 ]\n",
      "  [ 97.46875  101.734375 100.60156 ]\n",
      "  [101.734375 106.734375 100.734375]\n",
      "  ...\n",
      "  [225.36719  227.36719  224.63281 ]\n",
      "  [225.90234  227.90234  224.90234 ]\n",
      "  [218.53516  220.26953  217.40234 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[171.86719  170.86719  166.86719 ]\n",
      "  [174.07422  174.07422  172.20703 ]\n",
      "  [159.63281  156.       152.13281 ]\n",
      "  ...\n",
      "  [227.33594  229.73438  226.60156 ]\n",
      "  [230.36719  232.10156  231.23438 ]\n",
      "  [230.66797  231.80078  233.40234 ]]\n",
      "\n",
      " [[165.6211   164.6211   160.6211  ]\n",
      "  [153.96094  152.60156  153.28125 ]\n",
      "  [164.19922  159.69922  156.69922 ]\n",
      "  ...\n",
      "  [228.39844  233.39844  229.39844 ]\n",
      "  [226.32031  226.32031  226.32031 ]\n",
      "  [233.03906  235.03906  234.03906 ]]\n",
      "\n",
      " [[165.95312  164.95312  160.95312 ]\n",
      "  [157.33984  156.33984  154.33984 ]\n",
      "  [155.91406  151.41406  148.41406 ]\n",
      "  ...\n",
      "  [238.72656  243.72656  239.72656 ]\n",
      "  [239.2461   239.2461   237.2461  ]\n",
      "  [232.82031  234.82031  233.82031 ]]]\n",
      "The label:\n",
      " b'dog'\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iteration = 0\n",
    "\n",
    "# The map() applies the process_image function on each sample in train_dataset, so the features and label of each sample in train_dataset is retrieved.\n",
    "train_dataset_features_label = train_dataset.map(process_image)\n",
    "\n",
    "# At each iteration, the retrieved features and label of a sample is stored in img and label variables respectively, in sequence.\n",
    "for img, label in train_dataset_features_label.take(3):\n",
    "    print('For the train set image/file at index ',iteration)\n",
    "    print('The features:\\n', img.numpy())\n",
    "    print('The label:\\n', label.numpy())\n",
    "    print('\\n\\n')\n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale the features of each image (into the range between 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the train set image/file at index  0\n",
      "The features:\n",
      " [[[0.90539217 0.90539217 0.9132353 ]\n",
      "  [0.9112745  0.9112745  0.90882355]\n",
      "  [0.91764706 0.91764706 0.91764706]\n",
      "  ...\n",
      "  [0.8419118  0.8144608  0.79093134]\n",
      "  [0.8392157  0.8039216  0.78431374]\n",
      "  [0.8352941  0.80784315 0.78431374]]\n",
      "\n",
      " [[0.902451   0.902451   0.9102941 ]\n",
      "  [0.9112745  0.9112745  0.9191176 ]\n",
      "  [0.91780025 0.91780025 0.91780025]\n",
      "  ...\n",
      "  [0.8392157  0.8117647  0.7882353 ]\n",
      "  [0.83927697 0.8120098  0.7884804 ]\n",
      "  [0.8352941  0.80784315 0.78431374]]\n",
      "\n",
      " [[0.902451   0.90588236 0.9137255 ]\n",
      "  [0.90588236 0.90588236 0.90588236]\n",
      "  [0.91764706 0.91764706 0.91764706]\n",
      "  ...\n",
      "  [0.83985907 0.8124081  0.7888787 ]\n",
      "  [0.84313726 0.8156863  0.7921569 ]\n",
      "  [0.8352941  0.80784315 0.78431374]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.74289215 0.907598   0.9703431 ]\n",
      "  [0.7345588  0.9098039  0.9703431 ]\n",
      "  [0.75818014 0.91847426 0.9655331 ]\n",
      "  ...\n",
      "  [0.6884804  0.88848037 0.97083336]\n",
      "  [0.69240195 0.89240193 0.9747549 ]\n",
      "  [0.6960478  0.9000306  0.972549  ]]\n",
      "\n",
      " [[0.7585478  0.92083335 0.9759191 ]\n",
      "  [0.73449755 0.92058825 0.9737745 ]\n",
      "  [0.7173101  0.91804534 0.9700061 ]\n",
      "  ...\n",
      "  [0.6767157  0.89240193 0.97083336]\n",
      "  [0.6901961  0.8901961  0.972549  ]\n",
      "  [0.6936275  0.89362746 0.96813726]]\n",
      "\n",
      " [[0.70416665 0.9017157  0.9669118 ]\n",
      "  [0.77086395 0.9274816  0.9899816 ]\n",
      "  [0.7084252  0.9162684  0.97117037]\n",
      "  ...\n",
      "  [0.6921262  0.8948223  0.97717524]\n",
      "  [0.6924326  0.8924326  0.97478557]\n",
      "  [0.7005821  0.90058213 0.97509193]]]\n",
      "The label:\n",
      " b'cat'\n",
      "\n",
      "\n",
      "\n",
      "For the train set image/file at index  1\n",
      "The features:\n",
      " [[[0.04113051 0.00382966 0.00229779]\n",
      "  [0.0417289  0.00442804 0.00289618]\n",
      "  [0.03632717 0.00610352 0.00380572]\n",
      "  ...\n",
      "  [0.18302983 0.11397346 0.06196768]\n",
      "  [0.11600701 0.04402669 0.01168428]\n",
      "  [0.10041264 0.02697993 0.        ]]\n",
      "\n",
      " [[0.84146845 0.7150448  0.51545745]\n",
      "  [0.85269606 0.72655964 0.52472425]\n",
      "  [0.8652727  0.73308825 0.53837794]\n",
      "  ...\n",
      "  [0.87981004 0.7499234  0.56034005]\n",
      "  [0.87671566 0.7445313  0.5560968 ]\n",
      "  [0.88055015 0.7483657  0.5599313 ]]\n",
      "\n",
      " [[0.84552026 0.72431064 0.53891987]\n",
      "  [0.85012734 0.7403234  0.55041265]\n",
      "  [0.83038545 0.72058153 0.53234625]\n",
      "  ...\n",
      "  [0.90752435 0.7820341  0.5938907 ]\n",
      "  [0.8978401  0.76450676 0.58028495]\n",
      "  [0.8901961  0.77054226 0.5804841 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.9361673  0.7889706  0.56352633]\n",
      "  [0.94066614 0.7934695  0.56802523]\n",
      "  [0.9550982  0.80790156 0.5824573 ]\n",
      "  ...\n",
      "  [0.97844666 0.8255055  0.59413296]\n",
      "  [0.9841299  0.83118874 0.5998162 ]\n",
      "  [0.97801775 0.8250766  0.59370404]]\n",
      "\n",
      " [[0.9126216  0.77536666 0.55575883]\n",
      "  [0.9233638  0.78610885 0.566501  ]\n",
      "  [0.9171722  0.7799173  0.5603094 ]\n",
      "  ...\n",
      "  [0.96651345 0.8135723  0.58219975]\n",
      "  [0.963557   0.81061584 0.57924324]\n",
      "  [0.9640769  0.8111357  0.5797631 ]]\n",
      "\n",
      " [[0.87766546 0.7325674  0.5168811 ]\n",
      "  [0.8951746  0.7500766  0.53439033]\n",
      "  [0.89801526 0.75291723 0.53723097]\n",
      "  ...\n",
      "  [0.9240876  0.7711464  0.547617  ]\n",
      "  [0.9356474  0.7827062  0.56701994]\n",
      "  [0.95140934 0.7984681  0.5749387 ]]]\n",
      "The label:\n",
      " b'dog'\n",
      "\n",
      "\n",
      "\n",
      "For the train set image/file at index  2\n",
      "The features:\n",
      " [[[0.10364583 0.23477328 0.09779412]\n",
      "  [0.17420343 0.3019608  0.13072917]\n",
      "  [0.20931372 0.29181984 0.21700367]\n",
      "  ...\n",
      "  [0.80186886 0.74442405 0.7275735 ]\n",
      "  [0.8538297  0.83538604 0.84068626]\n",
      "  [0.8965993  0.9044424  0.8926777 ]]\n",
      "\n",
      " [[0.11868872 0.29469976 0.13621323]\n",
      "  [0.16470589 0.3056066  0.14068627]\n",
      "  [0.2049326  0.2912071  0.20193015]\n",
      "  ...\n",
      "  [0.81482846 0.7444547  0.705239  ]\n",
      "  [0.83673406 0.794087   0.78624386]\n",
      "  [0.8980392  0.90588236 0.89411765]]\n",
      "\n",
      " [[0.1654718  0.32356006 0.17781863]\n",
      "  [0.21688113 0.32840073 0.1938419 ]\n",
      "  [0.19491422 0.28903186 0.19534314]\n",
      "  ...\n",
      "  [0.811826   0.7605699  0.7294424 ]\n",
      "  [0.84923404 0.78943014 0.76170343]\n",
      "  [0.90637255 0.9119485  0.90787375]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.81960785 0.7019608  0.56764704]\n",
      "  [0.7967218  0.6599571  0.5070772 ]\n",
      "  [0.7599265  0.6310049  0.46335784]\n",
      "  ...\n",
      "  [0.39227942 0.20306373 0.0596201 ]\n",
      "  [0.5093137  0.3107843  0.07962622]\n",
      "  [0.4616115  0.25808823 0.06099878]]\n",
      "\n",
      " [[0.81311274 0.69938725 0.5660539 ]\n",
      "  [0.79929537 0.66375613 0.5103248 ]\n",
      "  [0.7345282  0.6051164  0.43648896]\n",
      "  ...\n",
      "  [0.41400123 0.19901961 0.03606005]\n",
      "  [0.56740195 0.34779412 0.1526348 ]\n",
      "  [0.59908086 0.37555146 0.1598652 ]]\n",
      "\n",
      " [[0.82833946 0.7342218  0.59304535]\n",
      "  [0.8154718  0.68998164 0.53262866]\n",
      "  [0.80977327 0.67643994 0.5311887 ]\n",
      "  ...\n",
      "  [0.532598   0.33210784 0.14224878]\n",
      "  [0.46510416 0.28765318 0.09442402]\n",
      "  [0.5208333  0.32083333 0.06740196]]]\n",
      "The label:\n",
      " b'cat'\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Self-define a function to scale the features of each image (into the range between 0 and 1). Since each pixel value of a color channel has maximum value of 255, we divide all pixel by 255 to perform scaling.\n",
    "def scale(image, label):\n",
    "    return image/255, label\n",
    "\n",
    "# Scale the features of each image stored in train_dataset_features_label, then save the outputs in train_dataset_features_label_scale\n",
    "train_dataset_features_label_scale = train_dataset_features_label.map(scale)\n",
    "iteration = 0\n",
    "\n",
    "# Show the scaled features and labels of provided image\n",
    "for image, label in train_dataset_features_label_scale.take(3):\n",
    "    print('For the train set image/file at index ',iteration)\n",
    "    print('The features:\\n', image.numpy())\n",
    "    print('The label:\\n', label.numpy())\n",
    "    print('\\n\\n')\n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform different operations on a dataset in one single line (using Tensorflow input pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the train set image/file at index  0\n",
      "The features:\n",
      " [[[0.7189951  0.7464461  0.36997548]\n",
      "  [0.7246017  0.74813116 0.3638174 ]\n",
      "  [0.7137255  0.7411765  0.3675245 ]\n",
      "  ...\n",
      "  [0.7019866  0.72833467 0.35015798]\n",
      "  [0.71059763 0.7302055  0.36942115]\n",
      "  [0.71115196 0.72683823 0.38566175]]\n",
      "\n",
      " [[0.70055145 0.73976713 0.36329657]\n",
      "  [0.7151482  0.7425992  0.3661286 ]\n",
      "  [0.70729166 0.74049    0.36492226]\n",
      "  ...\n",
      "  [0.69099265 0.72408086 0.35716912]\n",
      "  [0.704473   0.72408086 0.3711397 ]\n",
      "  [0.6993959  0.72025985 0.38833582]]\n",
      "\n",
      " [[0.6784314  0.7176471  0.34117648]\n",
      "  [0.69842124 0.7258722  0.34940162]\n",
      "  [0.68952876 0.72874445 0.35117093]\n",
      "  ...\n",
      "  [0.66041666 0.7069853  0.3529412 ]\n",
      "  [0.68625826 0.7215524  0.37253276]\n",
      "  [0.6862745  0.7176471  0.38535538]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.5170295  0.68026483 0.38969153]\n",
      "  [0.32928923 0.53282875 0.00992647]\n",
      "  [0.56155026 0.744492   0.46907648]\n",
      "  ...\n",
      "  [0.6569001  0.7903694  0.56205386]\n",
      "  [0.56078434 0.7137255  0.29793295]\n",
      "  [0.57408756 0.73479915 0.38698587]]\n",
      "\n",
      " [[0.52640647 0.67408663 0.36540478]\n",
      "  [0.31070486 0.535477   0.00705423]\n",
      "  [0.5772021  0.7452311  0.5035645 ]\n",
      "  ...\n",
      "  [0.6191521  0.7611414  0.4925427 ]\n",
      "  [0.5243174  0.6889007  0.2656164 ]\n",
      "  [0.4901798  0.6609796  0.29055032]]\n",
      "\n",
      " [[0.57454044 0.6874416  0.38085362]\n",
      "  [0.52252793 0.6978372  0.26085803]\n",
      "  [0.5361903  0.69562656 0.5049403 ]\n",
      "  ...\n",
      "  [0.55879766 0.6825722  0.41480258]\n",
      "  [0.5256405  0.68633    0.2714183 ]\n",
      "  [0.49886355 0.6825942  0.23636547]]]\n",
      "The label:\n",
      " b'dog'\n",
      "\n",
      "\n",
      "\n",
      "For the train set image/file at index  1\n",
      "The features:\n",
      " [[[0.7567622  0.831272   0.61558574]\n",
      "  [0.7463398  0.8208496  0.60516334]\n",
      "  [0.7620864  0.8365962  0.6209099 ]\n",
      "  ...\n",
      "  [0.7458946  0.8204044  0.60471815]\n",
      "  [0.774011   0.8485208  0.6328345 ]\n",
      "  [0.7552476  0.8297574  0.61407113]]\n",
      "\n",
      " [[0.76038605 0.83489585 0.6192096 ]\n",
      "  [0.7700071  0.8445169  0.6288306 ]\n",
      "  [0.74847674 0.82298654 0.6073003 ]\n",
      "  ...\n",
      "  [0.7550532  0.829563   0.61387676]\n",
      "  [0.74529433 0.81980413 0.6041178 ]\n",
      "  [0.7570466  0.8315564  0.6158701 ]]\n",
      "\n",
      " [[0.77281517 0.84732497 0.6316387 ]\n",
      "  [0.753821   0.8283308  0.61264455]\n",
      "  [0.7565918  0.8311016  0.61541533]\n",
      "  ...\n",
      "  [0.7624952  0.837005   0.62131876]\n",
      "  [0.75930417 0.83381397 0.6181277 ]\n",
      "  [0.7564932  0.831003   0.6153167 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.7538268  0.8283366  0.61265033]\n",
      "  [0.7477989  0.8223087  0.60662246]\n",
      "  [0.7701871  0.8446969  0.6290106 ]\n",
      "  ...\n",
      "  [0.74330765 0.81781745 0.6021312 ]\n",
      "  [0.7488492  0.823359   0.6076727 ]\n",
      "  [0.75416666 0.82867646 0.6129902 ]]\n",
      "\n",
      " [[0.7499454  0.8244552  0.60876894]\n",
      "  [0.75784695 0.83235675 0.6166705 ]\n",
      "  [0.74884534 0.82335514 0.6076689 ]\n",
      "  ...\n",
      "  [0.76593614 0.84044594 0.6247597 ]\n",
      "  [0.7707788  0.8452886  0.6296023 ]\n",
      "  [0.7505879  0.8250977  0.60941136]]\n",
      "\n",
      " [[0.76728135 0.84179115 0.62610483]\n",
      "  [0.7491316  0.8236414  0.60795516]\n",
      "  [0.74140626 0.81591606 0.6002298 ]\n",
      "  ...\n",
      "  [0.75980777 0.83431756 0.6186313 ]\n",
      "  [0.7507564  0.8252662  0.60957986]\n",
      "  [0.76623964 0.84074944 0.6250632 ]]]\n",
      "The label:\n",
      " b'dog'\n",
      "\n",
      "\n",
      "\n",
      "For the train set image/file at index  2\n",
      "The features:\n",
      " [[[0.90539217 0.90539217 0.9132353 ]\n",
      "  [0.9112745  0.9112745  0.90882355]\n",
      "  [0.91764706 0.91764706 0.91764706]\n",
      "  ...\n",
      "  [0.8419118  0.8144608  0.79093134]\n",
      "  [0.8392157  0.8039216  0.78431374]\n",
      "  [0.8352941  0.80784315 0.78431374]]\n",
      "\n",
      " [[0.902451   0.902451   0.9102941 ]\n",
      "  [0.9112745  0.9112745  0.9191176 ]\n",
      "  [0.91780025 0.91780025 0.91780025]\n",
      "  ...\n",
      "  [0.8392157  0.8117647  0.7882353 ]\n",
      "  [0.83927697 0.8120098  0.7884804 ]\n",
      "  [0.8352941  0.80784315 0.78431374]]\n",
      "\n",
      " [[0.902451   0.90588236 0.9137255 ]\n",
      "  [0.90588236 0.90588236 0.90588236]\n",
      "  [0.91764706 0.91764706 0.91764706]\n",
      "  ...\n",
      "  [0.83985907 0.8124081  0.7888787 ]\n",
      "  [0.84313726 0.8156863  0.7921569 ]\n",
      "  [0.8352941  0.80784315 0.78431374]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.74289215 0.907598   0.9703431 ]\n",
      "  [0.7345588  0.9098039  0.9703431 ]\n",
      "  [0.75818014 0.91847426 0.9655331 ]\n",
      "  ...\n",
      "  [0.6884804  0.88848037 0.97083336]\n",
      "  [0.69240195 0.89240193 0.9747549 ]\n",
      "  [0.6960478  0.9000306  0.972549  ]]\n",
      "\n",
      " [[0.7585478  0.92083335 0.9759191 ]\n",
      "  [0.73449755 0.92058825 0.9737745 ]\n",
      "  [0.7173101  0.91804534 0.9700061 ]\n",
      "  ...\n",
      "  [0.6767157  0.89240193 0.97083336]\n",
      "  [0.6901961  0.8901961  0.972549  ]\n",
      "  [0.6936275  0.89362746 0.96813726]]\n",
      "\n",
      " [[0.70416665 0.9017157  0.9669118 ]\n",
      "  [0.77086395 0.9274816  0.9899816 ]\n",
      "  [0.7084252  0.9162684  0.97117037]\n",
      "  ...\n",
      "  [0.6921262  0.8948223  0.97717524]\n",
      "  [0.6924326  0.8924326  0.97478557]\n",
      "  [0.7005821  0.90058213 0.97509193]]]\n",
      "The label:\n",
      " b'cat'\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the image dataset by storing the list of the directory of all image files of the dataset in the image_dataset variable, through providing the list as the input of tf.data.dataset.list_files(). Shuffle=False means you don't want to provide the directory of the images in a random sequence. Shuffle=True means you want to provide the directory of the images in a random sequence.\n",
    "images_dataset_new = tf.data.Dataset.list_files('deep-learning-keras-tf-tutorial/44_tf_data_pipeline/images/*/*', shuffle=False)\n",
    "\n",
    "train_set_new_OperationsInSingleLine = train_dataset.map(process_image).map(scale)\n",
    "iter = 0\n",
    "\n",
    "# Show the scaled features and labels of provided image\n",
    "for image, label in train_set_new_OperationsInSingleLine.take(3):\n",
    "    print('For the train set image/file at index ',iter)\n",
    "    print('The features:\\n', image.numpy())\n",
    "    print('The label:\\n', label.numpy())\n",
    "    print('\\n\\n')\n",
    "    iter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
