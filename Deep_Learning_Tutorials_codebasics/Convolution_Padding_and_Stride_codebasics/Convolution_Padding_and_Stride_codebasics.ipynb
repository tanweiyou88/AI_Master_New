{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Padding and Stride\n",
    "\n",
    "Link to the Youtube tutorial video: https://www.youtube.com/watch?v=oDAPkZ53zKk&list=PLeo1K3hjS3uu7CxAacxVndI4bE_o3BDtO&index=25\n",
    "\n",
    "1) **Padding:**\n",
    "    1) Padding is a hyperparameter of the neural network\n",
    "    2) <img src=\"hidden\\photo1.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 400px;\"/>  <br />\n",
    "        1) When we apply a convolutional filter on an input(original) image to perform convolution operation, the output feature map will have a smaller dimension (the dimension can be calculated using a formula) compared to the input image. This is called valid convolution OR valid padding.\n",
    "    2)  <img src=\"hidden\\photo2.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 400px;\"/>  <br />\n",
    "        1) The problem with valid convolution is that the pixels on the corner don't get to play important role in feature detection. For example, on the left side, the highlighted pixel participates only in one convolution operation which is this corner. Whereas, on the right side, the highlighted pixel gets to participate in multiple convolution operations. Hence, valid convolution is basically not ideal as the corner pixels are not playing an important role for feature detection in your image classification.\n",
    "    2)  <img src=\"hidden\\photo3.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 400px;\"/>  <br />\n",
    "        1) To solve this valid convolution problem, we can pad the original image (In this case, with 1x1 padding [padding of 1]). So on each side of the original image, we add 1 row & 1 column of empty pixels (You can put some values like -1 in the empty pixel to represent a black background). Now, you apply 3x3 convolutional filter from top left corner until bottom right corner. Now, even the corner pixels will play a lot of role because they will contribute/involve in multiple convolution operations while detecting these features. The dimension of the original image was 5x7, but we pad the original image with 1x1 padding (added two columns and two rows), so it now its dimension is 7x9. By using the formula, after performing convolution operation using the 3x3 filter on the 7x9 padded image, the output feature map has dimension of 5x7 (you get the dimension of original image back again). Hence, you're kind of preserving that image back and at the same time the corner pixels gets to play a fair role in the feature detection. This is called same convolution.\n",
    "    3) Summary of padding:\n",
    "        1) <img src=\"hidden\\photo4.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 400px;\"/>  <br />\n",
    "            1) Valid convolution means no padding. \n",
    "            2) Same convolution means pad such that the dimension of the output feature map is same as the dimension of input image.\n",
    "            3) When you're using tensorflow API, you either supply a value of \"same\" or \"valid\" as the padding argument for same convolution and valid convolution respectively. By default, the padding is \"valid\", which means there will be no padding (valid convolution). You can modify padding type based on your situation & dataset.\n",
    "\n",
    "1) **Stride:**\n",
    "    1) Stride is a hyperparameter of the neural network.\n",
    "    2) <img src=\"hidden\\photo5.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 400px;\"/>  <br />\n",
    "        1) When we move a filter by 1 pixel (from top left corner, in the right or down direction, to the bottom right corner) to perform operation, it is called stride=(1,1) [stride of one by one]. \n",
    "    3) <img src=\"hidden\\photo6.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 400px;\"/>  <br />    \n",
    "        1) You can also have a more stride [EG: stride=(2,2)]. For stride=(2,2), you move a filter by 2 pixels.\n",
    "        2) When you're using tensorflow API, you can specify the stride size. By default, the stride size is stride(1,1). You can modify stride size based on your situation & dataset."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
