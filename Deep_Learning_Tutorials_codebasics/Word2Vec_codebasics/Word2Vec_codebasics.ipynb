{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec using gensim\n",
    "\n",
    "Link to the Youtube tutorial video: https://www.youtube.com/watch?v=Q2NtCcqmIww&list=PLeo1K3hjS3uu7CxAacxVndI4bE_o3BDtO&index=43\n",
    "\n",
    "1) **Introduction to Word2Vec:**\n",
    "    1) Word2vec is a technique in natural language processing (NLP) for obtaining vector representations of words. These vectors capture information about the meaning of the word based on the surrounding words. The word2vec algorithm estimates these representations by modeling text in a large corpus. Once trained, such a model can detect synonymous words or suggest additional words for a partial sentence. Word2vec was developed by Tomáš Mikolov and colleagues at Google and published in 2013.\n",
    "    2) Word2vec represents a word as a high-dimension vector of numbers which capture relationships between words. In particular, words which appear in similar contexts are mapped to vectors which are nearby as measured by cosine similarity. This indicates the level of semantic similarity between the words, so for example the vectors for walk and ran are nearby, as are those for \"but\" and \"however\", and \"Berlin\" and \"Germany\".\n",
    "    3) Reference: https://en.wikipedia.org/wiki/Word2vec\n",
    "\n",
    "2) **Insights of this tutorial:**\n",
    "    1) The outputs of model.wv.most_similar() are the vocabularies (that the word2vec model learnt & claimed to be similar to the input word [in this case, the input word is \"bad\"]) & their corresponding similarity score to the input word.\n",
    "    2) The similarity can be in terms of the relationship such as antonym, synonym, adjective,...\n",
    "    3) The similarity score is a value that is related to 2 words.\n",
    "    4) The outputs of model.wv.similarity() is the similarity score between 2 given words.\n",
    "    5) When the similarity score between 2 given words is positive, it means the 2 words are similar in certain ways.\n",
    "    6) When the similarity score between 2 given words is negative, it means the 2 words are not similar in certain ways.\n",
    "    7) When the similarity score between 2 given words equals 1, it means the 2 words are exactly same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim # gensim library is an natural language processing (NLP) library for python\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the dataset (Amazon product review dataset)\n",
    "\n",
    "The Amazon product review dataset is a subset of Amazon reviews from the cell phone and accessories categories. The data is stored as a JSON file and can be read by using pandas (because pandas support reading JSON file). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A30TL5EWN6DFXT</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>christina</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>They look good and stick good! I just don't li...</td>\n",
       "      <td>4</td>\n",
       "      <td>Looks Good</td>\n",
       "      <td>1400630400</td>\n",
       "      <td>05 21, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASY55RVNIL0UD</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>emily l.</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These stickers work like the review says they ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Really great product.</td>\n",
       "      <td>1389657600</td>\n",
       "      <td>01 14, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2TMXE2AFO7ONB</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>Erica</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These are awesome and make my phone look so st...</td>\n",
       "      <td>5</td>\n",
       "      <td>LOVE LOVE LOVE</td>\n",
       "      <td>1403740800</td>\n",
       "      <td>06 26, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AWJ0WZQYMYFQ4</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>JM</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>Item arrived in great time and was in perfect ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Cute!</td>\n",
       "      <td>1382313600</td>\n",
       "      <td>10 21, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATX7CZYFXI1KW</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>patrice m rogoza</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>awesome! stays on, and looks great. can be use...</td>\n",
       "      <td>5</td>\n",
       "      <td>leopard home button sticker for iphone 4s</td>\n",
       "      <td>1359849600</td>\n",
       "      <td>02 3, 2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin      reviewerName helpful  \\\n",
       "0  A30TL5EWN6DFXT  120401325X         christina  [0, 0]   \n",
       "1   ASY55RVNIL0UD  120401325X          emily l.  [0, 0]   \n",
       "2  A2TMXE2AFO7ONB  120401325X             Erica  [0, 0]   \n",
       "3   AWJ0WZQYMYFQ4  120401325X                JM  [4, 4]   \n",
       "4   ATX7CZYFXI1KW  120401325X  patrice m rogoza  [2, 3]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  They look good and stick good! I just don't li...        4   \n",
       "1  These stickers work like the review says they ...        5   \n",
       "2  These are awesome and make my phone look so st...        5   \n",
       "3  Item arrived in great time and was in perfect ...        4   \n",
       "4  awesome! stays on, and looks great. can be use...        5   \n",
       "\n",
       "                                     summary  unixReviewTime   reviewTime  \n",
       "0                                 Looks Good      1400630400  05 21, 2014  \n",
       "1                      Really great product.      1389657600  01 14, 2014  \n",
       "2                             LOVE LOVE LOVE      1403740800  06 26, 2014  \n",
       "3                                      Cute!      1382313600  10 21, 2013  \n",
       "4  leopard home button sticker for iphone 4s      1359849600   02 3, 2013  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset as dataframe\n",
    "df = pd.read_json(\"Cell_Phones_and_Accessories_5.json\", lines=True) # lines=True means read the JSON file as a JSON object per line (also means 1 line in the JSON file is 1 JSON object)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         They look good and stick good! I just don't li...\n",
      "1         These stickers work like the review says they ...\n",
      "2         These are awesome and make my phone look so st...\n",
      "3         Item arrived in great time and was in perfect ...\n",
      "4         awesome! stays on, and looks great. can be use...\n",
      "                                ...                        \n",
      "194434    Works great just like my original one. I reall...\n",
      "194435    Great product. Great packaging. High quality a...\n",
      "194436    This is a great cable, just as good as the mor...\n",
      "194437    I really like it becasue it works well with my...\n",
      "194438    product as described, I have wasted a lot of m...\n",
      "Name: reviewText, Length: 194439, dtype: object\n",
      "\n",
      "\n",
      "They look good and stick good! I just don't like the rounded shape because I was always bumping it and Siri kept popping up and it was irritating. I just won't buy a product like this again\n"
     ]
    }
   ],
   "source": [
    "# The \"reviewText\" is the only column/feature we are interested. We use the feature to train a word2vec model so that we get word embeddings (our main goal in this tutorial) as the by-product.\n",
    "# Show the \"reviewText\" feature\n",
    "print(df.reviewText)\n",
    "print('\\n')\n",
    "\n",
    "# Show the 1st sample of the \"reviewText\" feature\n",
    "print(df.reviewText[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing using gensim\n",
    "\n",
    "The preprocessing module of gensim will extract each vocabulary/word from all given sentences, and:\n",
    "1) Change the capital letter into small letter\n",
    "2) Ignore the spacing\n",
    "3) Ignore the punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: Explain the working principle of gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first sentence/sample in the \"reviewText\" feature/column:\n",
      "They look good and stick good! I just don't like the rounded shape because I was always bumping it and Siri kept popping up and it was irritating. I just won't buy a product like this again\n",
      "\n",
      "The output of the gensim preprocesing module on the same sentence:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['they',\n",
       " 'look',\n",
       " 'good',\n",
       " 'and',\n",
       " 'stick',\n",
       " 'good',\n",
       " 'just',\n",
       " 'don',\n",
       " 'like',\n",
       " 'the',\n",
       " 'rounded',\n",
       " 'shape',\n",
       " 'because',\n",
       " 'was',\n",
       " 'always',\n",
       " 'bumping',\n",
       " 'it',\n",
       " 'and',\n",
       " 'siri',\n",
       " 'kept',\n",
       " 'popping',\n",
       " 'up',\n",
       " 'and',\n",
       " 'it',\n",
       " 'was',\n",
       " 'irritating',\n",
       " 'just',\n",
       " 'won',\n",
       " 'buy',\n",
       " 'product',\n",
       " 'like',\n",
       " 'this',\n",
       " 'again']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The first sentence/sample in the \"reviewText\" feature/column:')\n",
    "print(df.reviewText[0])\n",
    "\n",
    "print('\\nThe output of the gensim preprocesing module on the same sentence:')\n",
    "gensim.utils.simple_preprocess(df.reviewText[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the \"reviewText\" feature/column using gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review_text dataset/dataframe (contains the preprocessed \"reviewText\" feature/column using gensim):\n",
      " 0         [they, look, good, and, stick, good, just, don...\n",
      "1         [these, stickers, work, like, the, review, say...\n",
      "2         [these, are, awesome, and, make, my, phone, lo...\n",
      "3         [item, arrived, in, great, time, and, was, in,...\n",
      "4         [awesome, stays, on, and, looks, great, can, b...\n",
      "                                ...                        \n",
      "194434    [works, great, just, like, my, original, one, ...\n",
      "194435    [great, product, great, packaging, high, quali...\n",
      "194436    [this, is, great, cable, just, as, good, as, t...\n",
      "194437    [really, like, it, becasue, it, works, well, w...\n",
      "194438    [product, as, described, have, wasted, lot, of...\n",
      "Name: reviewText, Length: 194439, dtype: object\n",
      "\n",
      "\n",
      "The review_text dataset/dataframe (contains the preprocessed \"reviewText\" feature/column using gensim) has 194439 sentences.\n"
     ]
    }
   ],
   "source": [
    "#  Preprocessing the \"reviewText\" feature/column using gensim, then store the output to the new dataframe called review_text. In the output dataframe, each row stores the extracted vocabularies/words for a sentence. apply() means apply the function stated after it to the data stated before it.\n",
    "review_text = df.reviewText.apply(gensim.utils.simple_preprocess)\n",
    "\n",
    "print('The review_text dataset/dataframe (contains the preprocessed \"reviewText\" feature/column using gensim):\\n', review_text)\n",
    "print('\\n\\nThe review_text dataset/dataframe (contains the preprocessed \"reviewText\" feature/column using gensim) has ' + str(review_text.shape[0]) + ' sentences.' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop the Word2Vec model (the model performs Word2Vec tasks) using gensim\n",
    "\n",
    "1) **Concept to perform Word2Vec:**\n",
    "    1) <img src=\"hidden\\context-window.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 400px;\"/>  <br />\n",
    "        1) This rectangle is called a context window. So you keep on moving the context window to generate your training samples. \n",
    "        2) For the traning samples: context words (features) -> target (ground truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The epochs setting of the word2vec model:  5\n"
     ]
    }
   ],
   "source": [
    "# Create a word2vec model using gensim\n",
    "model = gensim.models.Word2Vec(\n",
    "    window=10, # Specify the paramters for the context window. Window=10 means the context window, with the target word located at the center of the window, take 10 words before the target word & also 10 words after the target word.\n",
    "    min_count=2, # Basically if you have a sentence which has only one word, then don't use that sentence for training (Don't take that sentence to generate training samples). At least two words need to be present in a sentence in order to for the sentence to be considered for the training.\n",
    "    workers=4, # This parameter specifies how many CPU threads you want to use to train this word2vec model. If your CPU has 4 cores, then you can use four thread.\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize the word2vec model by building vocabulary using the given extracted words from a dataset.Build a vocabulary means build a unique list of words. progress per means when you are training your word2vec model, after how many words you want to see a progress bar or progress update\n",
    "model.build_vocab(review_text, progress_per = 100)\n",
    "\n",
    "# Show the epochs setting of the word2vec model. By default, the epochs is set to 5.\n",
    "print('The epochs setting of the word2vec model: ', model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61505193, 83868975)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the word2vec model. It takes the data in review_text for training. total_examples specifies the total number of samples in the provided data will be used for training (here, model.corpus_count=194439 samples/sentences will be used for training)\n",
    "model.train(review_text, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the trained Word2Vec model into a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as a file. Usually, after training a word2vec model, save it to a file so that you can then use/deploy this pre-trained model (saved in a file) in most of the occasions (NLP needs) in future.\n",
    "model.save(\"word2vec-amazon-cell-accessories-reviews-short.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the trained Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('terrible', 0.6819854378700256),\n",
       " ('shabby', 0.6476674675941467),\n",
       " ('horrible', 0.622264564037323),\n",
       " ('good', 0.5699361562728882),\n",
       " ('awful', 0.5582795739173889),\n",
       " ('sad', 0.5427185893058777),\n",
       " ('okay', 0.5424753427505493),\n",
       " ('crappy', 0.5264002680778503),\n",
       " ('poor', 0.5140402913093567),\n",
       " ('cheap', 0.5124132037162781)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deploy the model using .wv(word2vec), use most_similar() to find the vocabularies it has which are similar to the input word (the unseen data)\n",
    "model.wv.most_similar(\"bad\")\n",
    "\n",
    "# Insights:\n",
    "# 1) The outputs of model.wv.most_similar() are the vocabularies (that the word2vec model learnt & claimed to be similar to the input word [in this case, the input word is \"bad\"]) & their corresponding similarity score to the input word.\n",
    "# 2) The similarity can be in terms of the relationship such as antonym, synonym, adjective,...\n",
    "# 3) The similarity score is a value that is related to 2 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity score between the words of \"cheap\" and \"inexpensive\" : 0.5278502\n",
      "The similarity score between the words of \"great\" and \"good\" : 0.7875755\n",
      "The similarity score between the words of \"great\" and \"product\" : -0.03806456\n",
      "The similarity score between the words of \"product\" and \"product\" : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Print the similarity score (weightage) between 2 given words\n",
    "print('The similarity score between the words of \"cheap\" and \"inexpensive\" :', model.wv.similarity(w1 = \"cheap\", w2 = \"inexpensive\"))\n",
    "print('The similarity score between the words of \"great\" and \"good\" :', model.wv.similarity(w1 = \"great\", w2 = \"good\"))\n",
    "print('The similarity score between the words of \"great\" and \"product\" :', model.wv.similarity(w1 = \"great\", w2 = \"product\"))\n",
    "print('The similarity score between the words of \"product\" and \"product\" :', model.wv.similarity(w1 = \"product\", w2 = \"product\"))\n",
    "\n",
    "# Insights:\n",
    "# 1) The outputs of model.wv.similarity() is the similarity score between 2 given words.\n",
    "# 2) When the similarity score between 2 given words is positive, it means the 2 words are similar in certain ways.\n",
    "# 3) When the similarity score between 2 given words is negative, it means the 2 words are not similar in certain ways.\n",
    "# 4) When the similarity score between 2 given words equals 1, it means the 2 words are exactly same."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
