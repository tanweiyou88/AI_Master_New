{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding using Keras Embedding Layer\n",
    "\n",
    "Link to the Youtube tutorial video: https://www.youtube.com/watch?v=Fuw0wv3X-0o&list=PLeo1K3hjS3uu7CxAacxVndI4bE_o3BDtO&index=41\n",
    "\n",
    "1) **Important things to note for this tutorial:**\n",
    "    1) Using supervised learning method (EG: neural network here) to perform food review (sentiment) classification (Classify if a food review sentence is a positive or negative review) so that we can get word embedding as the by-product of the food review classification. \n",
    "    2) It is important to note here that our main goal in this food review classification tasks (tutorial) is to get word embedding (from the embedding layer of the neural network), not to get a good neural network for food review classification.\n",
    "    3) Word embedding are the parameters/weights in the neural network that used to perform the corresponding sentiment classification tasks.\n",
    "\n",
    "\n",
    "2) **Important concept of obtaining word embeddings from sentiment classification tasks using supervised learning approach:**\n",
    "    1) <img src=\"hidden\\photo2.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 450px;\"/>  <br />\n",
    "        1) The similar vocabularies/words (EG: Cummins & Dhoni are human name; Australia & Zimbabwe are country name) will have similar feature vector (The value of each feature is close to each other OR even same) \n",
    "    2) <img src=\"hidden\\photo3.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 450px;\"/>  <br />\n",
    "    3) <img src=\"hidden\\photo4.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 450px;\"/>  <br />\n",
    "    4) <img src=\"hidden\\photo5.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 450px;\"/>  <br />\n",
    "    5) <img src=\"hidden\\photo6.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 450px;\"/>  <br />\n",
    "    6) <img src=\"hidden\\photo7.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 450px;\"/>  <br />\n",
    "    7) <img src=\"hidden\\photo8.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 450px;\"/>  <br />\n",
    "    8) <img src=\"hidden\\photo9.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 450px;\"/>  <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume the reviews variable stores the features(reviews) of food review dataset (in total, we only gathered/have 10 food reviews in the dataset here)\n",
    "reviews = ['nice food',\n",
    "           'amazing restaurant',\n",
    "           'too good',\n",
    "           'just loved it!',\n",
    "           'will go again',\n",
    "           'horrible food',\n",
    "           'never go there',\n",
    "           'poor service',\n",
    "           'poor quality',\n",
    "           'needs improvement']\n",
    "\n",
    "# The label (ground truth) of each sample of food review dataset (representing each food review either is good [positve] or bad [negative])\n",
    "sentiment = np.array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert each word(vocabulary) into one-hot-encoding representation\n",
    "\n",
    "Vocabulary size refers to the total number of unique vocabulary/word available in a dataset (EG: the food review dataset, that consists of all food review sentences available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28, 15], [13, 23], [7, 4], [19, 24, 1], [4, 10, 29], [20, 15], [4, 10, 21], [19, 11], [19, 14], [7, 18]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the vocabulary size (The vocabulary size is set as 50 here). When you found there are vocabularies assigned with the same unique number, you increase your vocabulary size to solve the problem.\n",
    "vocab_size = 50\n",
    "\n",
    "# Encode all the food reviews into one-hot-encoding representation OR encoded vector, using one_hot(). one_hot(\"the words you want to convert into one-hot-encoding representation\", the vocabulary size = maximum word size). Then the one_hot() will assign a unique & fixed number (between 0 and the maximum word size provided) to each word provided. Internally, keras will convert the unique number into one-hot-encoding representation (EG:0, 0, 1, 0, ).\n",
    "encoded_reviews = [one_hot(d , 30) for d in reviews]\n",
    "print(encoded_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pad each food review sentence so that each food review sentence has same word/vocabulary size/number (so that later, the input layer of neural network can accept all the food review sentences)\n",
    "\n",
    "1) The image below shows the food review sentence consists of 3 vocabularies/words  <br />\n",
    "    <img src=\"hidden\\photo1.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 450px;\"/>  <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28 15  0]\n",
      " [13 23  0]\n",
      " [ 7  4  0]\n",
      " [19 24  1]\n",
      " [ 4 10 29]\n",
      " [20 15  0]\n",
      " [ 4 10 21]\n",
      " [19 11  0]\n",
      " [19 14  0]\n",
      " [ 7 18  0]]\n"
     ]
    }
   ],
   "source": [
    "# max_length refers to the maximum number of vocabulary/word that each sentence has\n",
    "max_length = 3\n",
    "\n",
    "# Pad each food review sentence so that each food review sentence has same word size (here, each food review sentence has word size of 3, even after padding)\n",
    "# pad_sequences(dataset_of_encoded_reviews, maximum_word_size_of_each_sentence, padding='post'_means_pad_until_the_end_if_the_word_size_of_the_sentence_does_not_reach_maximum)\n",
    "padded_reviews = pad_sequences(encoded_reviews, maxlen=max_length, padding='post')\n",
    "print(padded_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the food review dataset into features and ground truths variables respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The features variable containing the features of the food review dataset\n",
    "X = padded_reviews\n",
    "\n",
    "# The ground truths variable containing the ground truths of the food review dataset\n",
    "Y = sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop the neural network (model) to perform food review classification\n",
    "\n",
    "1) The neural network involved in this tutorial consists of 4 layers:\n",
    "    1) Layer 1: Input layer\n",
    "    2) Layer 2: Embedding layer\n",
    "    3) Layer 3: Flatten layer\n",
    "    4) Layer 4: Output layer\n",
    "2) <img src=\"hidden\\embedding_layer.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 450px;\"/>  <br />\n",
    "    1) An embedding vector is the result of multiplying a vocabulary feature vector (a row of feature vector in the embedding matrix corresponds to a vocabulary/word, which having the paramaters/weights that obtained at previous iteration or initialized at the begining [not the latest one]) and its one-hot-encoding representation. It is the feature vector of a vocabulary/word.\n",
    "    2) At the embedding layer (Emb.L), you can access all the embedding vectors.\n",
    "2) <img src=\"hidden\\flatten_layer.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 450px;\"/>  <br />\n",
    "    1) Once you get embedding vectors from your embedding layer, you want to flatten them into a 1D vector at the flatten layer (Flat.L). So the 3rd layer of the model is flatten layer.\n",
    "3) <img src=\"hidden\\output_layer.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 450px;\"/>  <br />\n",
    "    1) The layer after the flatten layer (4th layer of the model) is one neuron sigmoid activation function, so it will be a dense layer with a sigma activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\weiyo\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_17\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_17\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m4\u001b[0m)           │           \u001b[38;5;34m200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_16 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m13\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">213</span> (852.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m213\u001b[0m (852.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">213</span> (852.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m213\u001b[0m (852.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The feature vector of each vocabulary has size of 4 (means each vocabulary is embedded to have 4 features)\n",
    "embedded_vector_size = 4\n",
    "\n",
    "model = Sequential() # Create a neural network (model)\n",
    "model.add(Embedding(vocab_size, embedded_vector_size, input_shape = (max_length,), name='embedding')) # This layer is the 2nd layer of the model (after the 1st layer of the model called input layer, represented by the parameter: input_shape = (max_length,)), which is called embedding layer. name=\"embedding\" means we call this layer as embedding. The input of the embedding layer is a 1D array.\n",
    "model.add(Flatten()) # The 3rd layer of the model is flatten layer\n",
    "model.add(Dense(1,activation='sigmoid')) # The 4th layer of the model is output layer, having only 1 output neuron followed by a sigmoid function as the activation function\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) # usually we end up using adam as an optimizer. We use binary cross entropy here because the food review classification output is either 1 (the food review sentence is positive) or 0 (the food review sentence is negative)\n",
    "\n",
    "# Show the summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 1.0000 - loss: 0.6394\n",
      "The loss of the model:  0.6393623948097229\n",
      "The accuracy of the model:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, Y, epochs = 50, verbose = 0)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X, Y)\n",
    "\n",
    "print('The loss of the model: ', loss)\n",
    "print('The accuracy of the model: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access word embedding data\n",
    "\n",
    "<img src=\"hidden\\get-layer.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 450px;\"/>  <br />\n",
    "1) model.get_layer('embedding').get_weights()[0] returns the embedding matrix.\n",
    "2) In the embedding matrix, each row is a feature vector for a vocabulary.\n",
    "3) Each feature vector consists of 4 elements/weigths/values for 4 features respectively. \n",
    "4) There are 4 elements in each feature vector (EG: W1, W2, W3) because we set the embedded_vector_size = 4.\n",
    "5) Extra information: The way keras embedding layer works is during the process of solving the NLP task, it will compute the embeddings before flattening them for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weights variable has size of 50because the vocabulary size is set as 50.\n",
      "\n",
      "The word embedding data:\n",
      " [[ 2.06098016e-02  1.31514585e-02  1.66069753e-02  9.69321060e-04]\n",
      " [-8.36955979e-02 -8.04848596e-02 -8.16679299e-02  4.44321930e-02]\n",
      " [-2.42828485e-02  4.33177389e-02  5.34787029e-03 -3.58751640e-02]\n",
      " [ 3.15174498e-02  2.91176699e-02 -1.29669793e-02  4.40440327e-03]\n",
      " [ 2.62911953e-02  3.16390805e-02  3.79479453e-02 -8.36459696e-02]\n",
      " [-4.00184765e-02 -7.80218840e-03 -2.77729388e-02  1.41248442e-02]\n",
      " [-5.89197874e-03  8.27502459e-04  3.67890857e-02 -4.81783524e-02]\n",
      " [ 7.49501586e-03 -7.80901685e-03 -1.34583348e-02 -5.24856057e-03]\n",
      " [-2.69686338e-02  3.42876352e-02  2.72996686e-02  2.50132568e-02]\n",
      " [-2.31710821e-03  4.51819338e-02 -2.03402527e-02  2.37979181e-02]\n",
      " [ 2.68387478e-02  8.90167803e-03  1.17291128e-02  8.87636095e-03]\n",
      " [-2.93559637e-02 -9.54880118e-02 -4.72217724e-02  4.60438989e-02]\n",
      " [ 4.16595861e-03  1.53562762e-02 -3.87539864e-02  4.57806475e-02]\n",
      " [-2.10163817e-02  3.82121988e-02 -2.63247620e-02 -5.27491383e-02]\n",
      " [-9.47650746e-02 -8.75207633e-02 -3.71085331e-02  6.15656711e-02]\n",
      " [-3.69494893e-02  8.70412774e-03  3.44583727e-02 -3.34299654e-02]\n",
      " [ 4.16357554e-02  9.99703258e-03  3.00997831e-02  2.78644301e-02]\n",
      " [ 4.26330827e-02 -4.50073555e-03 -3.28445658e-02  9.78385285e-03]\n",
      " [-5.93439117e-02 -5.33109438e-03  1.40862656e-04  3.69731262e-02]\n",
      " [ 5.50558791e-02 -3.51684876e-02  5.67634776e-02  3.83100174e-02]\n",
      " [ 8.65578428e-02 -2.88530905e-03  9.42695700e-03  6.24962822e-02]\n",
      " [ 4.47400613e-03  9.04781893e-02  8.87993425e-02 -9.33478475e-02]\n",
      " [ 3.77821811e-02 -3.18228826e-02 -1.31745227e-02  3.33247222e-02]\n",
      " [ 7.96146989e-02  3.76342027e-03  3.28932181e-02 -7.50109628e-02]\n",
      " [ 6.90541640e-02  9.95241255e-02  2.56240973e-03 -4.69213501e-02]\n",
      " [-2.12342273e-02  4.07400392e-02 -3.35764512e-02 -4.62988280e-02]\n",
      " [-1.85222253e-02 -4.13070805e-02 -2.05651280e-02  4.82491590e-02]\n",
      " [-4.95272167e-02  1.45476498e-02 -3.56789678e-03 -1.21856555e-02]\n",
      " [-2.39222217e-02  9.99028236e-02 -9.77884084e-02 -8.18599109e-03]\n",
      " [-8.20232704e-02 -7.92889148e-02 -9.87097546e-02  5.67732900e-02]\n",
      " [-3.94520648e-02 -4.82104905e-02 -8.27096403e-04 -4.67633381e-02]\n",
      " [ 6.30602986e-03 -1.54252425e-02  3.54265086e-02 -3.15308571e-05]\n",
      " [ 2.74808295e-02  2.72650979e-02  4.75733541e-02 -3.12260631e-02]\n",
      " [ 2.71316878e-02 -2.02577841e-02  2.54745148e-02 -2.89584287e-02]\n",
      " [ 2.61274092e-02  1.89702250e-02 -5.76899201e-03 -2.52765063e-02]\n",
      " [-2.41197236e-02  2.47179605e-02 -2.23712921e-02 -1.67896859e-02]\n",
      " [-3.04304119e-02  3.89809944e-02  1.87716149e-02  1.06928349e-02]\n",
      " [ 3.20344046e-03  1.68427564e-02 -2.62415893e-02 -9.83327627e-03]\n",
      " [ 4.39981110e-02  1.29742362e-02 -9.00543854e-03 -8.89390707e-03]\n",
      " [ 2.75194533e-02  1.00130960e-03 -4.29438129e-02 -2.58056764e-02]\n",
      " [ 4.82580811e-03  3.18053029e-02 -1.79095976e-02 -4.09899354e-02]\n",
      " [-3.45742330e-02  3.53463404e-02 -7.62261078e-03  1.24075264e-03]\n",
      " [ 1.91217326e-02 -4.88124155e-02  3.12670507e-02  2.05204599e-02]\n",
      " [ 7.09353760e-03 -3.00421603e-02  1.72585584e-02 -4.15268913e-02]\n",
      " [ 1.65381171e-02  1.27487257e-03  3.96865495e-02 -6.13250583e-03]\n",
      " [-4.22999375e-02 -1.33728385e-02  1.06078871e-02  3.08184884e-02]\n",
      " [ 2.44126357e-02  2.15976276e-02 -4.74155322e-02 -1.32924207e-02]\n",
      " [-2.01558005e-02  4.74521779e-02 -4.69697826e-02 -2.08080057e-02]\n",
      " [ 2.00397633e-02 -2.33744625e-02  4.54840772e-02  3.53569053e-02]\n",
      " [-1.98327377e-03  2.38653272e-03 -2.56700162e-02  3.00189741e-02]]\n",
      "\n",
      "The unique number assigned to the vocabulary of \"nice\" is 28 , the feature vector of the vocabulary of \"nice\":\n",
      "[-0.02392222  0.09990282 -0.09778841 -0.00818599]\n",
      "\n",
      "The unique number assigned to the vocabulary of \"improvement\" is 18 , the feature vector of the vocabulary of \"improvement\":\n",
      "[-0.05934391 -0.00533109  0.00014086  0.03697313]\n"
     ]
    }
   ],
   "source": [
    "# model.get_layer('name_of_the_layer_you_give') retrieves the specified layer from the neural network, get_weights() returns the parameters/weights of that layer in 3D array. get_weights()[0] returns the parameters/weights of that layer in 2D array.\n",
    "weights = model.get_layer('embedding').get_weights()[0]\n",
    "\n",
    "print('The weights variable has size of ' + str(len(weights)) + 'because the vocabulary size is set as ' + str(vocab_size) + '.')\n",
    "print('\\nThe word embedding data:\\n', weights)\n",
    "\n",
    "print('\\nThe unique number assigned to the vocabulary of \"nice\" is ' + str(encoded_reviews[0][0]) + ' , the feature vector of the vocabulary of \"nice\":\\n' + str(weights[encoded_reviews[0][0]]))\n",
    "print('\\nThe unique number assigned to the vocabulary of \"improvement\" is ' + str(encoded_reviews[9][1]) + ' , the feature vector of the vocabulary of \"improvement\":\\n' + str(weights[encoded_reviews[9][1]]))\n",
    "\n",
    "# Insights:\n",
    "# \"nice\" and \"improvement\" are not the similar word (EG: nice is an adjective; improvement is a noun), so the value of the same row of their respective feature vectors should be different (the values of the same row of their respective feature vectors should not close to each other)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
