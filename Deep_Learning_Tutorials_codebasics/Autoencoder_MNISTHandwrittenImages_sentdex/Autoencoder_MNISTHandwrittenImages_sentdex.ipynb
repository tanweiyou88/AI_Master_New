{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder with MNIST Handwritten Image Dataset\n",
    "\n",
    "Link to the Youtube video tutorial:https://www.youtube.com/watch?v=JoR5HCs0n0s\n",
    "\n",
    "**Motivation to have an autoencoder:**\n",
    "1) We have this autoencoder so we've trained this encoder to take an image of 784 values/features (original feature dimension) and condense it down to 64 values/feature (new reduced feature dimension), yet still contain the same meaning (means both feature dimension can represent the same input image). Then, before we pass the features of a dataset through a different neural network for other tasks (EG: classification problem), if our training data are these MNIST images, we could actually feed the encoded 64 features (new reduced feature dimension) through the different neural network, rather than feeding the 784 features (original feature dimension) through the different neural network. Thus, making the different neural network easier to learn the features of the dataset. Also, we can change the data types and more.\n",
    "\n",
    "**Insights of this tutorial:**\n",
    "1) We trained an autoencoder to just take images and encode (compress the features[data] OR reduce the feature dimension) them into the meaning of that image. \n",
    "2) Since an autoencoder is an unsupervised machine learning model, it has just kind of figured out like this group of images goes together and here's the generic version of that group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set consists of 60000 samples(images), each image has dimension of 28x28 (pixels), with 1 color channel (grayscale). This means each image has 28 x 28 = 784 features.\n",
      "The train set consists of 10000 samples(images), each image has dimension of 28x28 (pixels), with 1 color channel (grayscale). This means each image has 28 x 28 = 784 features.\n",
      "\n",
      "The features of the 1st sample in train set:\n",
      " [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"The train set consists of {X_train.shape[0]} samples(images), each image has dimension of {X_train.shape[1]}x{X_train.shape[2]} (pixels), with 1 color channel (grayscale). This means each image has {X_train.shape[1]} x {X_train.shape[2]} = {str(X_train.shape[1]*X_train.shape[1])} features.\")\n",
    "print(f\"The train set consists of {X_test.shape[0]} samples(images), each image has dimension of {X_test.shape[1]}x{X_test.shape[2]} (pixels), with 1 color channel (grayscale). This means each image has {X_test.shape[1]} x {X_test.shape[2]} = {str(X_test.shape[1]*X_test.shape[1])} features.\")\n",
    "color_channel = 1 # The samples(images) of the dataset are in grayscale (consists of only 1 color channel)\n",
    "\n",
    "# Show the image of 1st sample in the train set\n",
    "plt.imshow(X_train[0], cmap=\"gray\")\n",
    "\n",
    "# Show the features of 1st sample in the train set\n",
    "print('\\nThe features of the 1st sample in train set:\\n', X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale data\n",
    "\n",
    "1) Scale the features (pixel values) of each image into the range between 0 and 1, by dividing with 255 (because each pixel value has minimum value of 0 and maximum value of 255).\n",
    "2) Data scaling makes a neural network performs better (related to the concept of gradient descent & backpropagation)\n",
    "3) For neural network, we generally like to keep data between -1 and 1 OR 0 and 1. In this case, it is between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The features of the 1st sample in the scaled train set:\n",
      " [[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01176471 0.07058824 0.07058824 0.07058824 0.49411765 0.53333333\n",
      "  0.68627451 0.10196078 0.65098039 1.         0.96862745 0.49803922\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.11764706 0.14117647 0.36862745 0.60392157\n",
      "  0.66666667 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      "  0.88235294 0.6745098  0.99215686 0.94901961 0.76470588 0.25098039\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.19215686 0.93333333 0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.98431373\n",
      "  0.36470588 0.32156863 0.32156863 0.21960784 0.15294118 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.07058824 0.85882353 0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.99215686 0.77647059 0.71372549 0.96862745 0.94509804\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.31372549 0.61176471 0.41960784 0.99215686\n",
      "  0.99215686 0.80392157 0.04313725 0.         0.16862745 0.60392157\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.05490196 0.00392157 0.60392157\n",
      "  0.99215686 0.35294118 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.54509804\n",
      "  0.99215686 0.74509804 0.00784314 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.04313725\n",
      "  0.74509804 0.99215686 0.2745098  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.1372549  0.94509804 0.88235294 0.62745098 0.42352941 0.00392157\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.31764706 0.94117647 0.99215686 0.99215686 0.46666667\n",
      "  0.09803922 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.17647059 0.72941176 0.99215686 0.99215686\n",
      "  0.58823529 0.10588235 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.0627451  0.36470588 0.98823529\n",
      "  0.99215686 0.73333333 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.97647059\n",
      "  0.99215686 0.97647059 0.25098039 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.18039216 0.50980392 0.71764706 0.99215686\n",
      "  0.99215686 0.81176471 0.00784314 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.15294118 0.58039216 0.89803922 0.99215686 0.99215686 0.99215686\n",
      "  0.98039216 0.71372549 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.09411765 0.44705882\n",
      "  0.86666667 0.99215686 0.99215686 0.99215686 0.99215686 0.78823529\n",
      "  0.30588235 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.09019608 0.25882353 0.83529412 0.99215686\n",
      "  0.99215686 0.99215686 0.99215686 0.77647059 0.31764706 0.00784314\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.07058824 0.67058824 0.85882353 0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.76470588 0.31372549 0.03529412 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.21568627 0.6745098\n",
      "  0.88627451 0.99215686 0.99215686 0.99215686 0.99215686 0.95686275\n",
      "  0.52156863 0.04313725 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.53333333 0.99215686\n",
      "  0.99215686 0.99215686 0.83137255 0.52941176 0.51764706 0.0627451\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_scaled = X_train / 255\n",
    "X_test_scaled = X_test / 255\n",
    "\n",
    "# Show the image of 1st sample in the scaled train set\n",
    "plt.imshow(X_train_scaled[0], cmap=\"gray\")\n",
    "\n",
    "# Show the features of 1st sample in the scaled train set\n",
    "print('\\nThe features of the 1st sample in the scaled train set:\\n', X_train_scaled[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build an autoencoder\n",
    "\n",
    "1) The autoencoder involved in this tutorial consists of an encoder and a decoder.\n",
    "2) The autoencoder is used to perform condensation (dimensionality reduction) of the features of dataset.\n",
    "3) There's like a million ways that you could you can make an autoencoder. Literally the only thing that matters is that you map input to input.\n",
    "4) The encoder of an autoencoder is made up by a neural network.\n",
    "5) The decoder of an autoencoder is made up by a neural network.\n",
    "\n",
    "**Motivation to have an autoencoder:**\n",
    "1) We have this autoencoder so we've trained this encoder to take an image of 784 values/features (original feature dimension) and condense it down to 64 values/feature (new reduced feature dimension), yet still contain the same meaning (means both feature dimension can represent the same input image). Then, before we pass the features of a dataset through a different neural network for other tasks (EG: classification problem), if our training data are these MNIST images, we could actually feed the encoded 64 features (new reduced feature dimension) through the different neural network, rather than feeding the 784 features (original feature dimension) through the different neural network. Thus, making the different neural network easier to learn the features of the dataset. Also, we can change the data types and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "\n",
    "1) Develop the encoder of the autoencoder using functional model\n",
    "2) The encoder receives an input image, then condense (reduce the dimensionality) the features (represented by a longer vector) of the input image into new set of features with lower dimensions(size) (represented by a shorter vector) by using neural network. The dimensionality reduction concept here is similar to the one of principal component analysis (PCA), just the method of performing the dimensionality reduction is different.\n",
    "3) You can build the encoder with multiple dense(hidden) layers. A dense layer consists of neurons that provide a vector of N dimensions/elements, where N refers to the number of neurons in that dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input layer of the encoder of the autoencoder. Syntax-> encoder_input = keras.Input(shape = (dimension of the image,dimension of the image, color channel number of the image[3 for rgb, 1 for grayscale]), name=\"name of the layer\")\n",
    "encoder_input = keras.Input(shape = (X_train.shape[1],X_train.shape[2], color_channel), name=\"img\")\n",
    "# Define the flatten layer to flatten the features from 2D into 1D, so that each flattened features can be fed to the neural network for processing (same concept as using ANN to perform image classification). We provide encoder_input to this flatten layer as input.\n",
    "x = keras.layers.Flatten()(encoder_input)\n",
    "# Define the output layer of the encoder of the autoencoder. The output layer consists of 64 output neurons to provide a vector of 64 dimensions (64 elements in that output vector). This means, the encoder condense the original 28x28=784 features into new 64 features, which can be used to represent all samples in the dataset. The encoder output layer is also called bottleneck, the middle layer of the autoencoder.\n",
    "encoder_output = keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "\n",
    "# Build an encoder model using the layers from encoder_input to encoder_output (optional to have this line, based on your application)\n",
    "encoder = keras.Model(encoder_input, encoder_output, name=\"encoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "\n",
    "1) Develop the decoder of the autoencoder using functional model\n",
    "2) The decoder receives the new reduced features provided at the bottleneck as the input, then uses it to generate (transform back to) the flattened features of the corresponding input image by using neural network, followed by reshaping the flattened features generated by the decoder into the dimensions  same as the original input image. (so that the features generated by the decoder can be visualized at the dimensions same as the original input image).\n",
    "3) You can build the decoder with multiple dense(hidden) layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input layer of the decoder of the autoencoder. We provide encoder_output (contains the new reduced features [here, the new reduce features is a vector of 64 dimensions/elements] provided by the bottleneck) to this decoder_input layer as input. Syntax-> encoder_input = keras.layers.Dense(shape = (the size of flattened features you want the decoder to provide, also equals to the number of neurons in the layer where each neuron provide an element/feature), activation=\"the type of activation function\") \n",
    "decoder_input = keras.layers.Dense(X_train.shape[1]*X_train.shape[2], activation=\"relu\")(encoder_output) # Same as-> decoder_input = keras.layers.Dense(784, activation=\"relu\")(encoder_output)\n",
    "\n",
    "# Define the output layer of the decoder of the autoencoder. We provide decoder_input (contains the flattened features generated by the decoder using the new reduced features provided at the bottleneck) to this decoder_output layer as input. This decoder_output layer is used to reshape the flattened features generated by the decoder (using the new reduced features provided at the bottleneck) from 1D into multiple-D with taking into account the color channel numbers, so that the features generated by the decoder can be used to visualize the corresponding image at the desired dimensions (here, at the dimensions same as the original input(image)).\n",
    "decoder_output = keras.layers.Reshape((X_train.shape[1],X_train.shape[2],color_channel))(decoder_input) # Same as-> decoder_output = keras.layers.Reshape((28,28,1))(decoder_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder (Encoder + Decoder)\n",
    "\n",
    "The autoencoder consists of encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\weiyo\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"autoencoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ img (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ img (\u001b[38;5;33mInputLayer\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m50,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │        \u001b[38;5;34m50,960\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,200</span> (395.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,200\u001b[0m (395.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,200</span> (395.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,200\u001b[0m (395.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the optimizer (hyperparameter) to build the autoencoder\n",
    "opt = keras.optimizers.Adam(\n",
    "    learning_rate=0.001, # Set the learning rate\n",
    "    decay=1e-6) # Set the decay rate\n",
    "\n",
    "# Build an autoencoder model using the layers from encoder_input to decoder_output\n",
    "autoencoder = keras.Model(encoder_input, decoder_output, name=\"autoencoder\")\n",
    "\n",
    "# Compile the autoencoder model, using the defined optimizer and mean squared error (MSE) as the cost function of each epoch\n",
    "autoencoder.compile(\n",
    "    opt, \n",
    "    loss=\"mse\")\n",
    "\n",
    "# Show the summary(details) of the autoencoder model\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the autoencoder\n",
    "\n",
    "1) In convention, when we train an ANN to perform image classification tasks, we use syntax-> model.fit(X_train, Y_train). This is because for each sample in X_train, the ANN is trained with the features of the sample to make prediction on the label on the sample. The predicted label of the sample (provided by the ANN) is compared with the ground truth label of the sample in Y_train, to calculate the loss for the sample.\n",
    "2) However, for autoencoder, when we train an autoencoder to perform dimensionality reduction tasks, we use syntax-> model.fit(X_train, X_train). This is because for each sample in X_train, the autoencoder is trained with the original features (large feature dimension) of the sample to reduce the original features into new reduced features (smaller feature dimension). To calculate the loss for the sample, the decoder of the autoencoder generates (decompress/transform back to) the features of the sample (in the same feature dimension as its original (ground truth) one) using the new reduced features provided by the bottleneck of the autoencoder. Then, the features of the sample generated by the decoder is compared with the original features (ground truth) of the sample to calculate the loss for the sample. \n",
    "3) When an autoencoder is trained, it means its encoder is trained, and also means its decoder is trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0287 - val_loss: 0.0124\n",
      "Epoch 2/3\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.0122 - val_loss: 0.0117\n",
      "Epoch 3/3\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.0116 - val_loss: 0.0115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2481bb985f0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the autoencoder\n",
    "autoencoder.fit(X_train_scaled, X_train_scaled, epochs=3, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply the autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the trained encoder to perform dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "------------Before applying the trained encoder:------------\n",
      "The original (ground truth) scaled features of the 1st sample in test set:\n",
      " [[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.32941176 0.7254902  0.62352941 0.59215686 0.23529412 0.14117647\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.87058824 0.99607843 0.99607843 0.99607843 0.99607843 0.94509804\n",
      "  0.77647059 0.77647059 0.77647059 0.77647059 0.77647059 0.77647059\n",
      "  0.77647059 0.77647059 0.66666667 0.20392157 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.2627451  0.44705882 0.28235294 0.44705882 0.63921569 0.89019608\n",
      "  0.99607843 0.88235294 0.99607843 0.99607843 0.99607843 0.98039216\n",
      "  0.89803922 0.99607843 0.99607843 0.54901961 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.06666667\n",
      "  0.25882353 0.05490196 0.2627451  0.2627451  0.2627451  0.23137255\n",
      "  0.08235294 0.9254902  0.99607843 0.41568627 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.3254902  0.99215686 0.81960784 0.07058824 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.08627451\n",
      "  0.91372549 1.         0.3254902  0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.50588235\n",
      "  0.99607843 0.93333333 0.17254902 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.23137255 0.97647059\n",
      "  0.99607843 0.24313725 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.52156863 0.99607843\n",
      "  0.73333333 0.01960784 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.03529412 0.80392157 0.97254902\n",
      "  0.22745098 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.49411765 0.99607843 0.71372549\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.29411765 0.98431373 0.94117647 0.22352941\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.0745098  0.86666667 0.99607843 0.65098039 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01176471 0.79607843 0.99607843 0.85882353 0.1372549  0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14901961 0.99607843 0.99607843 0.30196078 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.12156863\n",
      "  0.87843137 0.99607843 0.45098039 0.00392157 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.52156863\n",
      "  0.99607843 0.99607843 0.20392157 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.23921569 0.94901961\n",
      "  0.99607843 0.99607843 0.20392157 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.4745098  0.99607843\n",
      "  0.99607843 0.85882353 0.15686275 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.4745098  0.99607843\n",
      "  0.81176471 0.07058824 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n",
      "\n",
      "The number of dimension of the original (ground truth) scaled features of the 1st sample in test set: 784\n",
      "\n",
      "------------After applying the trained encoder:------------\n",
      "The prediction (new reduced features) made by the trained encoder on the 1st sample in the test set:\n",
      " [0.19615154 0.748357   0.         0.73828346 1.9513392  2.2640915\n",
      " 4.52065    0.41431808 0.887052   0.5940707  0.50783074 0.\n",
      " 2.7545917  1.1800133  0.09166135 1.307997   0.25068015 1.5341151\n",
      " 0.66470796 1.1056595  1.1680374  0.9632978  0.75131524 1.0127228\n",
      " 0.9210677  0.67101365 2.492184   1.07923    1.3722901  0.9468854\n",
      " 0.985739   0.         1.4603765  1.5190259  0.8184886  1.3676283\n",
      " 0.64620745 0.38395423 1.0757706  0.4204656  0.         0.67669064\n",
      " 0.23855855 1.6840208  0.49020386 0.9786315  0.         1.7683352\n",
      " 1.3986595  1.8156985  1.3035331  0.57070875 0.         0.97629434\n",
      " 2.0366297  0.639341   1.8487175  1.2248949  0.8547702  0.\n",
      " 0.44484863 0.82526195 0.9970782  1.2690254 ]\n",
      "\n",
      "The number of dimension of the new reduced features of the 1st sample in test set, provided by the trained encoder: 64\n",
      "\n",
      "------------Insights:------------\n",
      "The trained encoder reduce the feature dimension of the 1st sample in test set from 784 into 64.\n",
      "The trained encoder compress/reduce the feature dimension of the sample by 91.83673469387756 %.\n",
      "In other words, the trained encoder compress/reduce the feature dimension of the sample to 8.16326530612245 %.\n"
     ]
    }
   ],
   "source": [
    "# Use the trained encoder to predict (perform dimensionality reduction. Here, the encoder is trained to reduce feature dimension from 784 features into 64 features) a sample in test set. The encoder output (new reduced features) can be obtained at the bottleneck (the middle layer of the autoencoder). \".reshape(-1, 28, 28, 1)])[0]\" is used to perform some reshaping because here we only make prediction on 1 sample, but the model.predict() functions accepts inputs and provide outputs as a list.\n",
    "bottleneck = encoder.predict([X_test_scaled[0].reshape(-1, X_test_scaled.shape[1], X_test_scaled.shape[2], color_channel)])[0] # bottleneck is a hidden (dense) layer with neurons, at the middle of an autoencoder, that provides the encoder output (new reduced features)\n",
    "\n",
    "print(\"------------Before applying the trained encoder:------------\")\n",
    "# Show the original (ground truth) scaled features of the 1st sample in test set\n",
    "print(f\"The original (ground truth) scaled features of the 1st sample in test set:\\n\", X_test_scaled[0])\n",
    "\n",
    "# Show the number of dimension of the original (ground truth) scaled features of the 1st sample in test set\n",
    "print(f\"\\nThe number of dimension of the original (ground truth) scaled features of the 1st sample in test set: {str(X_test_scaled.shape[1]*X_test_scaled.shape[2])}\")\n",
    "\n",
    "print(\"\\n------------After applying the trained encoder:------------\")\n",
    "# Show the prediction (new reduced features) of the 1st sample in test set\n",
    "print(f\"The prediction (new reduced features) made by the trained encoder on the 1st sample in the test set:\\n\", bottleneck)\n",
    "\n",
    "# Show the number of dimension of the original (ground truth) scaled features of the 1st sample in test set\n",
    "print(f\"\\nThe number of dimension of the new reduced features of the 1st sample in test set, provided by the trained encoder: {bottleneck.shape[0]}\")\n",
    "\n",
    "\n",
    "print(\"\\n------------Insights:------------\")\n",
    "# Show that the trained encoder performs dimensionality reduction on the features of the 1st sample in test set\n",
    "print(f\"The trained encoder reduce the feature dimension of the 1st sample in test set from {str(X_test_scaled.shape[1]*X_test_scaled.shape[2])} into {bottleneck.shape[0]}.\")\n",
    "print(f\"The trained encoder compress/reduce the feature dimension of the sample by {str( (X_test_scaled.shape[1]*X_test_scaled.shape[2]*color_channel - bottleneck.shape[0])/(X_test_scaled.shape[1]*X_test_scaled.shape[2]*color_channel) * 100)} %.\")\n",
    "print(f\"In other words, the trained encoder compress/reduce the feature dimension of the sample to {str( bottleneck.shape[0] / (X_test_scaled.shape[1]*X_test_scaled.shape[2]*color_channel) * 100)} %.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the image of the sample using the new reduced features provided by the encoder at the bottleneck as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2481bb85730>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the image of the sample using its reduced new features. The reduced new features provided by the trained encoder is in flatten from (1D) of 64 features. But we need to provide 2D features to plt.imshow() to visualize the image of the sample. Hence, we reshape the new reduced features (consists 64 features) from  of 1D form of length 64 into 2D form of 8x8, using \"reshape((int(example.shape[0]**(1/2)), int(example.shape[0]**(1/2)))\".\n",
    "plt.imshow(bottleneck.reshape((int(bottleneck.shape[0]**(1/2)), int(bottleneck.shape[0]**(1/2)))), cmap=\"gray\")\n",
    "\n",
    "# Extra information:\n",
    "# print(int(example.shape[0]**(1/2))) = 8\n",
    "# print(example.shape[0]**(1/2)) = 8.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the trained autoencoder to reduce the feature dimension of an input image, followed by reconstructing/generating/decompressing the features of the corresponding image back from its new reduced features provided by the encoder at the bottleneck as output \n",
    "\n",
    "Prediction made by an autoencoder here refers to use the encoder to reduce the feature dimension of the input image, then use the decoder to generate the features of the corresponding image (by using the new reduced features provided by the encoder at the bottleneck as output) at the dimensions same as the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002481E95DC60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n"
     ]
    }
   ],
   "source": [
    "# Use the trained autoencoder (encoder + decoder) to predict the 1st sample in test set. Prediction made by an autoencoder here refers to use the encoder to reduce the feature dimension of the input image, then use the decoder to generate the features of the corresponding image (by using the reduced new features provided at the bottleneck) at the dimensions same as the input image.\n",
    "autoencoder_prediction = autoencoder.predict([X_test_scaled[0].reshape(-1, X_test_scaled.shape[1], X_test_scaled.shape[2], color_channel)])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the image of the sample predicted by the autoencoder (using the features generated by the decoder from the new reduced features provided by the encoder at the bottleneck as output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2481e960740>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the image of the sample using the features generated by the decoder\n",
    "plt.imshow(autoencoder_prediction, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the image of the sample using the original (ground truth) scaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2481ea6dbb0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the image of the sample using its original (ground truth) scaled features\n",
    "plt.imshow(X_test_scaled[0], cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
