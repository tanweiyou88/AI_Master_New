{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Imbalanced Dataset in Machine Learning\n",
    "\n",
    "Link to the Youtube tutorial video: https://www.youtube.com/watch?v=JnlM4yLFNuo&list=PLeo1K3hjS3uu7CxAacxVndI4bE_o3BDtO&index=21\n",
    "\n",
    "**You have to try different methods to handle imbalanced dataset to identify which method works the best for your scenario (dataset), because in machine learning there is no guarantee a method can work best for a scenario without trying all alternative methods.**\n",
    "\n",
    "**Motivation of handling imbalance dataset before training a machine learning model:**\n",
    "1) Fraud detection is a common problem that people try to solve in the field of machine learning but when you're training your model with a training set for fraud transaction you will often find that you will have 10 000 good transaction and only one will be fraud.\n",
    "2) This creates an imbalance in your dataset and even if you write a simple python prediction function which returns false all the time, even with that stupid function, you can get 99 percent accuracy because majority of the transactions are not fraud but on the other hand what you care about is the fraud transaction.<br />\n",
    "    <img src=\"hidden\\photo1.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 400px;\"/>  <br />\n",
    "3) Hence, although accuracy is 99 percent, the function is still performing horribly because it's not telling you what is fraud.\n",
    "4) So this kind of imbalance creates a lot of issues in the field of machine learning and there are ways to tackle that. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2880</th>\n",
       "      <td>2187-PKZAY</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>12</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>79.95</td>\n",
       "      <td>1043.4</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>4988-IQIGL</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>75.35</td>\n",
       "      <td>75.35</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5408</th>\n",
       "      <td>6407-GSJNL</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>51</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>...</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>24.95</td>\n",
       "      <td>1288</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3890</th>\n",
       "      <td>3886-CERTZ</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>72</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>One year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>109.25</td>\n",
       "      <td>8109.8</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5461</th>\n",
       "      <td>1221-GHZEP</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>62</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Two year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>65.10</td>\n",
       "      <td>3846.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      customerID  gender  SeniorCitizen Partner Dependents  tenure  \\\n",
       "2880  2187-PKZAY    Male              0      No         No      12   \n",
       "3495  4988-IQIGL    Male              1      No         No       1   \n",
       "5408  6407-GSJNL  Female              0      No         No      51   \n",
       "3890  3886-CERTZ  Female              0     Yes         No      72   \n",
       "5461  1221-GHZEP  Female              0      No         No      62   \n",
       "\n",
       "     PhoneService MultipleLines InternetService       OnlineSecurity  ...  \\\n",
       "2880          Yes            No     Fiber optic                   No  ...   \n",
       "3495          Yes           Yes     Fiber optic                   No  ...   \n",
       "5408          Yes           Yes              No  No internet service  ...   \n",
       "3890          Yes           Yes     Fiber optic                   No  ...   \n",
       "5461          Yes            No             DSL                  Yes  ...   \n",
       "\n",
       "         DeviceProtection          TechSupport          StreamingTV  \\\n",
       "2880                   No                   No                   No   \n",
       "3495                   No                   No                   No   \n",
       "5408  No internet service  No internet service  No internet service   \n",
       "3890                  Yes                  Yes                  Yes   \n",
       "5461                   No                  Yes                   No   \n",
       "\n",
       "          StreamingMovies        Contract PaperlessBilling  \\\n",
       "2880                  Yes  Month-to-month              Yes   \n",
       "3495                   No  Month-to-month              Yes   \n",
       "5408  No internet service        Two year               No   \n",
       "3890                  Yes        One year              Yes   \n",
       "5461                  Yes        Two year              Yes   \n",
       "\n",
       "                  PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
       "2880  Bank transfer (automatic)          79.95        1043.4    No  \n",
       "3495           Electronic check          75.35         75.35   Yes  \n",
       "5408  Bank transfer (automatic)          24.95          1288    No  \n",
       "3890           Electronic check         109.25        8109.8   Yes  \n",
       "5461               Mailed check          65.10       3846.75    No  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the dataset into a dataframe called df\n",
    "df = pd.read_csv(\"customer_churn.csv\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing (Part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender               object\n",
       "SeniorCitizen         int64\n",
       "Partner              object\n",
       "Dependents           object\n",
       "tenure                int64\n",
       "PhoneService         object\n",
       "MultipleLines        object\n",
       "InternetService      object\n",
       "OnlineSecurity       object\n",
       "OnlineBackup         object\n",
       "DeviceProtection     object\n",
       "TechSupport          object\n",
       "StreamingTV          object\n",
       "StreamingMovies      object\n",
       "Contract             object\n",
       "PaperlessBilling     object\n",
       "PaymentMethod        object\n",
       "MonthlyCharges      float64\n",
       "TotalCharges         object\n",
       "Churn                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the customerID feature/column from the df dataframe. Inplace is set as true so that after dropping customerID feature, it will update the same df dataframe.\n",
    "df.drop('customerID', axis='columns', inplace=True)\n",
    "\n",
    "# Show all the columns of df dataframe and their corresponding data type\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['29.85', '1889.5', '108.15', ..., '346.45', '306.6', '6844.5'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# According to df.dtypes, TotalCharges is object type. This code also shows that TotalCharges is a string in 1D array\n",
    "df.TotalCharges.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         29.85\n",
       "1       1889.50\n",
       "2        108.15\n",
       "3       1840.75\n",
       "4        151.65\n",
       "         ...   \n",
       "7038    1990.50\n",
       "7039    7362.90\n",
       "7040     346.45\n",
       "7041     306.60\n",
       "7042    6844.50\n",
       "Name: TotalCharges, Length: 7043, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert TotalCharges feature/column in df dataframe from a 1D array of string into a 1D array of number column (in the format of numpy series) using to_numeric(). errors='coerce' means the using to_numeric() will convert for whatever columns with ignoring errors (EG: NaN)\n",
    "pd.to_numeric(df.TotalCharges, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "7038    False\n",
       "7039    False\n",
       "7040    False\n",
       "7041    False\n",
       "7042    False\n",
       "Name: TotalCharges, Length: 7043, dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# isnull() will tell if the value of each row is null or not\n",
    "pd.to_numeric(df.TotalCharges, errors='coerce').isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>52.55</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>20.25</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>80.85</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>25.75</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>56.05</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>19.85</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>25.35</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>20.00</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5218</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>One year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>19.70</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6670</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>73.35</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6754</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>61.90</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "488   Female              0     Yes        Yes       0           No   \n",
       "753     Male              0      No        Yes       0          Yes   \n",
       "936   Female              0     Yes        Yes       0          Yes   \n",
       "1082    Male              0     Yes        Yes       0          Yes   \n",
       "1340  Female              0     Yes        Yes       0           No   \n",
       "3331    Male              0     Yes        Yes       0          Yes   \n",
       "3826    Male              0     Yes        Yes       0          Yes   \n",
       "4380  Female              0     Yes        Yes       0          Yes   \n",
       "5218    Male              0     Yes        Yes       0          Yes   \n",
       "6670  Female              0     Yes        Yes       0          Yes   \n",
       "6754    Male              0      No        Yes       0          Yes   \n",
       "\n",
       "         MultipleLines InternetService       OnlineSecurity  \\\n",
       "488   No phone service             DSL                  Yes   \n",
       "753                 No              No  No internet service   \n",
       "936                 No             DSL                  Yes   \n",
       "1082               Yes              No  No internet service   \n",
       "1340  No phone service             DSL                  Yes   \n",
       "3331                No              No  No internet service   \n",
       "3826               Yes              No  No internet service   \n",
       "4380                No              No  No internet service   \n",
       "5218                No              No  No internet service   \n",
       "6670               Yes             DSL                   No   \n",
       "6754               Yes             DSL                  Yes   \n",
       "\n",
       "             OnlineBackup     DeviceProtection          TechSupport  \\\n",
       "488                    No                  Yes                  Yes   \n",
       "753   No internet service  No internet service  No internet service   \n",
       "936                   Yes                  Yes                   No   \n",
       "1082  No internet service  No internet service  No internet service   \n",
       "1340                  Yes                  Yes                  Yes   \n",
       "3331  No internet service  No internet service  No internet service   \n",
       "3826  No internet service  No internet service  No internet service   \n",
       "4380  No internet service  No internet service  No internet service   \n",
       "5218  No internet service  No internet service  No internet service   \n",
       "6670                  Yes                  Yes                  Yes   \n",
       "6754                  Yes                   No                  Yes   \n",
       "\n",
       "              StreamingTV      StreamingMovies  Contract PaperlessBilling  \\\n",
       "488                   Yes                   No  Two year              Yes   \n",
       "753   No internet service  No internet service  Two year               No   \n",
       "936                   Yes                  Yes  Two year               No   \n",
       "1082  No internet service  No internet service  Two year               No   \n",
       "1340                  Yes                   No  Two year               No   \n",
       "3331  No internet service  No internet service  Two year               No   \n",
       "3826  No internet service  No internet service  Two year               No   \n",
       "4380  No internet service  No internet service  Two year               No   \n",
       "5218  No internet service  No internet service  One year              Yes   \n",
       "6670                  Yes                   No  Two year               No   \n",
       "6754                   No                   No  Two year              Yes   \n",
       "\n",
       "                  PaymentMethod  MonthlyCharges TotalCharges Churn  \n",
       "488   Bank transfer (automatic)           52.55                 No  \n",
       "753                Mailed check           20.25                 No  \n",
       "936                Mailed check           80.85                 No  \n",
       "1082               Mailed check           25.75                 No  \n",
       "1340    Credit card (automatic)           56.05                 No  \n",
       "3331               Mailed check           19.85                 No  \n",
       "3826               Mailed check           25.35                 No  \n",
       "4380               Mailed check           20.00                 No  \n",
       "5218               Mailed check           19.70                 No  \n",
       "6670               Mailed check           73.35                 No  \n",
       "6754  Bank transfer (automatic)           61.90                 No  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show all samples in df dataset whose TotalCharges feature is null\n",
    "df[pd.to_numeric(df.TotalCharges, errors='coerce').isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                                 Female\n",
       "SeniorCitizen                               0\n",
       "Partner                                   Yes\n",
       "Dependents                                Yes\n",
       "tenure                                      0\n",
       "PhoneService                               No\n",
       "MultipleLines                No phone service\n",
       "InternetService                           DSL\n",
       "OnlineSecurity                            Yes\n",
       "OnlineBackup                               No\n",
       "DeviceProtection                          Yes\n",
       "TechSupport                               Yes\n",
       "StreamingTV                               Yes\n",
       "StreamingMovies                            No\n",
       "Contract                             Two year\n",
       "PaperlessBilling                          Yes\n",
       "PaymentMethod       Bank transfer (automatic)\n",
       "MonthlyCharges                          52.55\n",
       "TotalCharges                                 \n",
       "Churn                                      No\n",
       "Name: 488, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the Nth sample information using iloc[]. i means integer, loc means location.\n",
    "df.iloc[488]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the value of TotalCharges feature of the Nth sample\n",
    "df.iloc[488][\"TotalCharges\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7032, 20)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save all samples in df dataframe whose TotalCharges feature is not null to the new dataframe called df1\n",
    "df1 = df[df.TotalCharges!=' ']\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weiyo\\AppData\\Local\\Temp\\ipykernel_6240\\1610378798.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.TotalCharges = pd.to_numeric(df1.TotalCharges)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert TotalCharges feature/column in df1 dataframe from a 1D array of string into a 1D array of number column (in the format of numpy series) using to_numeric(), then update to df1 dataframe.\n",
    "df1.TotalCharges = pd.to_numeric(df1.TotalCharges)\n",
    "\n",
    "# Confirm TotalCharges feature/column in df1 dataframe now is in the format of number column (numpy series)\n",
    "df1.TotalCharges.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of Number of Customer vs Tenure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Customer Churn Dataset Visualization (No. of Customer vs Tenure)')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the tenure feature values of samples/customers in df1 dataframe who are not leaving (churn=No), then save them into a numpy series called tenure_churn_no\n",
    "tenure_churn_no = df1[df1.Churn=='No'].tenure\n",
    "\n",
    "# Get the tenure feature values of samples/customers in df1 dataframe who are leaving (churn=Yes), then save them into a numpy series called tenure_churn_yes\n",
    "tenure_churn_yes = df1[df1.Churn=='Yes'].tenure\n",
    "\n",
    "# Plot a histogram with information of tenure_churn_no & tenure_churn_yes. Green for tenure_churn_yes, red for tenure_churn_no\n",
    "plt.hist([tenure_churn_yes, tenure_churn_no], color=['red', 'green'], label=['Churn=Yes (leaving)', 'Churn=No (not leaving)'])\n",
    "plt.legend() # show the legend on the histogram\n",
    "plt.xlabel('Tenure') # show the x-axis label on the histogram\n",
    "plt.ylabel('Number of Customers') # show the y-axis label on the histogram\n",
    "plt.title('Customer Churn Dataset Visualization (No. of Customer vs Tenure)') # show the title on the histogram\n",
    "\n",
    "# Insights from the histogram: \n",
    "# 1) Majority of the customer with long tenure (with the company) are not leaving (Churn=No)\n",
    "# 2) Majority of the customer with short tenure (with the company) are leaving (Churn=Yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of Number of Customer vs Monthly Charge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Customer Churn Dataset Visualization (No. of Customer vs Monthly Charge)')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the tenure feature values of samples/customers in df1 dataframe who are not leaving (churn=No), then save them into a numpy series called tenure_churn_no\n",
    "mc_churn_no = df1[df1.Churn=='No'].MonthlyCharges\n",
    "\n",
    "# Get the tenure feature values of samples/customers in df1 dataframe who are leaving (churn=Yes), then save them into a numpy series called tenure_churn_yes\n",
    "mc_churn_yes = df1[df1.Churn=='Yes'].MonthlyCharges\n",
    "\n",
    "# Plot a histogram with information of tenure_churn_no & tenure_churn_yes. Green for tenure_churn_yes, red for tenure_churn_no\n",
    "plt.hist([mc_churn_yes, mc_churn_no], rwidth=0.95, color=['red', 'green'], label=['Churn=Yes (leaving)', 'Churn=No (not leaving)'])\n",
    "plt.legend() # show the legend on the histogram\n",
    "plt.xlabel('Monthly Charges') # show the x-axis label on the histogram\n",
    "plt.ylabel('Number of Customers') # show the y-axis label on the histogram\n",
    "plt.title('Customer Churn Dataset Visualization (No. of Customer vs Monthly Charge)') # show the title on the histogram\n",
    "\n",
    "# Insights from the histogram: \n",
    "# 1) Majority of customers who are not leaving have low monthly charge "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing (Part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender : ['Female' 'Male']\n",
      "Partner : ['Yes' 'No']\n",
      "Dependents : ['No' 'Yes']\n",
      "PhoneService : ['No' 'Yes']\n",
      "MultipleLines : ['No phone service' 'No' 'Yes']\n",
      "InternetService : ['DSL' 'Fiber optic' 'No']\n",
      "OnlineSecurity : ['No' 'Yes' 'No internet service']\n",
      "OnlineBackup : ['Yes' 'No' 'No internet service']\n",
      "DeviceProtection : ['No' 'Yes' 'No internet service']\n",
      "TechSupport : ['No' 'Yes' 'No internet service']\n",
      "StreamingTV : ['No' 'Yes' 'No internet service']\n",
      "StreamingMovies : ['No' 'Yes' 'No internet service']\n",
      "Contract : ['Month-to-month' 'One year' 'Two year']\n",
      "PaperlessBilling : ['Yes' 'No']\n",
      "PaymentMethod : ['Electronic check' 'Mailed check' 'Bank transfer (automatic)'\n",
      " 'Credit card (automatic)']\n",
      "Churn : ['No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "# Self-defined a function to print the unique values in the object-type categorical columns/features of the input dataframe\n",
    "def print_unique_col_values(df):\n",
    "    for column in df: # Iterate each column in the input dataframe\n",
    "        if df[column].dtypes=='object': # If the column/feature is object type\n",
    "            print(f'{column} : {df[column].unique()}') # Print its unique values using python f format string\n",
    "\n",
    "# Show the unique values of each categorical column/feature in df1 dataframe\n",
    "print_unique_col_values(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender : ['Female' 'Male']\n",
      "Partner : ['Yes' 'No']\n",
      "Dependents : ['No' 'Yes']\n",
      "PhoneService : ['No' 'Yes']\n",
      "MultipleLines : ['No' 'Yes']\n",
      "InternetService : ['DSL' 'Fiber optic' 'No']\n",
      "OnlineSecurity : ['No' 'Yes']\n",
      "OnlineBackup : ['Yes' 'No']\n",
      "DeviceProtection : ['No' 'Yes']\n",
      "TechSupport : ['No' 'Yes']\n",
      "StreamingTV : ['No' 'Yes']\n",
      "StreamingMovies : ['No' 'Yes']\n",
      "Contract : ['Month-to-month' 'One year' 'Two year']\n",
      "PaperlessBilling : ['Yes' 'No']\n",
      "PaymentMethod : ['Electronic check' 'Mailed check' 'Bank transfer (automatic)'\n",
      " 'Credit card (automatic)']\n",
      "Churn : ['No' 'Yes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weiyo\\AppData\\Local\\Temp\\ipykernel_6240\\227830700.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.replace('No internet service', 'No', inplace=True) # Alternative way: df1 = df1.replace('No internet service', 'No')\n",
      "C:\\Users\\weiyo\\AppData\\Local\\Temp\\ipykernel_6240\\227830700.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.replace('No phone service', 'No', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Replace 'No internet service' with 'No' in df1 dataframe, then update/modify df1 dataframe (because 'No internet service' and 'No' has same meaning in this context)\n",
    "df1.replace('No internet service', 'No', inplace=True) # Alternative way: df1 = df1.replace('No internet service', 'No')\n",
    "\n",
    "# Replace 'No phone service' with 'No' in df1 dataframe, then update/modify df1 dataframe (because 'No phone service' and 'No' has same meaning in this context)\n",
    "df1.replace('No phone service', 'No', inplace=True) \n",
    "\n",
    "# Show the unique values of each categorical column/feature in df1 dataframe\n",
    "print_unique_col_values(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning models do not understand text so we have to convert every text or a string type of column into a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender: ['Female' 'Male']\n",
      "SeniorCitizen: [0 1]\n",
      "Partner: [1 0]\n",
      "Dependents: [0 1]\n",
      "tenure: [ 1 34  2 45  8 22 10 28 62 13 16 58 49 25 69 52 71 21 12 30 47 72 17 27\n",
      "  5 46 11 70 63 43 15 60 18 66  9  3 31 50 64 56  7 42 35 48 29 65 38 68\n",
      " 32 55 37 36 41  6  4 33 67 23 57 61 14 20 53 40 59 24 44 19 54 51 26 39]\n",
      "PhoneService: [0 1]\n",
      "MultipleLines: [0 1]\n",
      "InternetService: ['DSL' 'Fiber optic' 'No']\n",
      "OnlineSecurity: [0 1]\n",
      "OnlineBackup: [1 0]\n",
      "DeviceProtection: [0 1]\n",
      "TechSupport: [0 1]\n",
      "StreamingTV: [0 1]\n",
      "StreamingMovies: [0 1]\n",
      "Contract: ['Month-to-month' 'One year' 'Two year']\n",
      "PaperlessBilling: [1 0]\n",
      "PaymentMethod: ['Electronic check' 'Mailed check' 'Bank transfer (automatic)'\n",
      " 'Credit card (automatic)']\n",
      "MonthlyCharges: [29.85 56.95 53.85 ... 63.1  44.2  78.7 ]\n",
      "TotalCharges: [  29.85 1889.5   108.15 ...  346.45  306.6  6844.5 ]\n",
      "Churn: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weiyo\\AppData\\Local\\Temp\\ipykernel_6240\\2395137406.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df1[col].replace({'Yes' : 1, 'No' : 0}, inplace = True) # Replace the unique values of the categorical column with 'Yes' with 1 & 'No' with 0\n",
      "C:\\Users\\weiyo\\AppData\\Local\\Temp\\ipykernel_6240\\2395137406.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df1[col].replace({'Yes' : 1, 'No' : 0}, inplace = True) # Replace the unique values of the categorical column with 'Yes' with 1 & 'No' with 0\n",
      "C:\\Users\\weiyo\\AppData\\Local\\Temp\\ipykernel_6240\\2395137406.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[col].replace({'Yes' : 1, 'No' : 0}, inplace = True) # Replace the unique values of the categorical column with 'Yes' with 1 & 'No' with 0\n"
     ]
    }
   ],
   "source": [
    "# Create a variable that contains the name of categorical columns/features whose unique values are 'Yes' and 'No'\n",
    "yes_no_columns = ['Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'OnlineSecurity', 'OnlineBackup', \n",
    "                  'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'PaperlessBilling', 'Churn']\n",
    "\n",
    "for col in yes_no_columns: # Iterate each categrotical column name\n",
    "    df1[col].replace({'Yes' : 1, 'No' : 0}, inplace = True) # Replace the unique values of the categorical column with 'Yes' with 1 & 'No' with 0 \n",
    "\n",
    "# Show the unique values of each column/feature in df1 dataframe. # cannot use print_unique_col_values(df1) anymore because now most categorical columns are not object-type anymore\n",
    "for col in df1: \n",
    "    print(f'{col}: {df1[col].unique()}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) When a categorical variable only has 2 values, then just replace them with 0 and 1 respectively.     <br \\>\n",
    "2) When a categorical variable only more than 2 values, then just convert them into one-hot-encoding representation (to avoid the ranking effect deteriorate machine learning performance).     <br \\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weiyo\\AppData\\Local\\Temp\\ipykernel_6240\\595001316.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df1['gender'].replace({'Female': 1, 'Male': 0}, inplace=True)\n",
      "C:\\Users\\weiyo\\AppData\\Local\\Temp\\ipykernel_6240\\595001316.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df1['gender'].replace({'Female': 1, 'Male': 0}, inplace=True)\n",
      "C:\\Users\\weiyo\\AppData\\Local\\Temp\\ipykernel_6240\\595001316.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['gender'].replace({'Female': 1, 'Male': 0}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Replace 'Female' with '1' & 'Male' with '0' in df1 dataframe, then update/modify df1 dataframe.\n",
    "df1['gender'].replace({'Female': 1, 'Male': 0}, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure',\n",
       "       'PhoneService', 'MultipleLines', 'OnlineSecurity', 'OnlineBackup',\n",
       "       'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies',\n",
       "       'PaperlessBilling', 'MonthlyCharges', 'TotalCharges', 'Churn',\n",
       "       'InternetService_DSL', 'InternetService_Fiber optic',\n",
       "       'InternetService_No', 'Contract_Month-to-month', 'Contract_One year',\n",
       "       'Contract_Two year', 'PaymentMethod_Bank transfer (automatic)',\n",
       "       'PaymentMethod_Credit card (automatic)',\n",
       "       'PaymentMethod_Electronic check', 'PaymentMethod_Mailed check'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the unique values of 'InternetService', 'Contract' & 'PaymentMethod' features in df1 dataframe into one-hot-encoding representation. Then save the whole dataframe results into a new dataframe called df2.\n",
    "df2 = pd.get_dummies(data = df1, columns= ['InternetService', 'Contract', 'PaymentMethod'], dtype=int)\n",
    "df2.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>...</th>\n",
       "      <th>InternetService_DSL</th>\n",
       "      <th>InternetService_Fiber optic</th>\n",
       "      <th>InternetService_No</th>\n",
       "      <th>Contract_Month-to-month</th>\n",
       "      <th>Contract_One year</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>PaymentMethod_Bank transfer (automatic)</th>\n",
       "      <th>PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>PaymentMethod_Electronic check</th>\n",
       "      <th>PaymentMethod_Mailed check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5990</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  SeniorCitizen  Partner  Dependents  tenure  PhoneService  \\\n",
       "4172       1              0        0           0       1             1   \n",
       "2642       1              0        1           0      47             1   \n",
       "2296       0              1        0           0       1             1   \n",
       "5990       0              0        0           1      36             1   \n",
       "\n",
       "      MultipleLines  OnlineSecurity  OnlineBackup  DeviceProtection  ...  \\\n",
       "4172              0               0             0                 0  ...   \n",
       "2642              0               0             0                 1  ...   \n",
       "2296              0               0             0                 0  ...   \n",
       "5990              0               0             1                 0  ...   \n",
       "\n",
       "      InternetService_DSL  InternetService_Fiber optic  InternetService_No  \\\n",
       "4172                    0                            0                   1   \n",
       "2642                    0                            1                   0   \n",
       "2296                    1                            0                   0   \n",
       "5990                    0                            1                   0   \n",
       "\n",
       "      Contract_Month-to-month  Contract_One year  Contract_Two year  \\\n",
       "4172                        1                  0                  0   \n",
       "2642                        1                  0                  0   \n",
       "2296                        1                  0                  0   \n",
       "5990                        1                  0                  0   \n",
       "\n",
       "      PaymentMethod_Bank transfer (automatic)  \\\n",
       "4172                                        0   \n",
       "2642                                        0   \n",
       "2296                                        0   \n",
       "5990                                        0   \n",
       "\n",
       "      PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
       "4172                                      0                               0   \n",
       "2642                                      0                               1   \n",
       "2296                                      0                               1   \n",
       "5990                                      0                               1   \n",
       "\n",
       "      PaymentMethod_Mailed check  \n",
       "4172                           1  \n",
       "2642                           0  \n",
       "2296                           0  \n",
       "5990                           0  \n",
       "\n",
       "[4 rows x 27 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                                       int64\n",
       "SeniorCitizen                                int64\n",
       "Partner                                      int64\n",
       "Dependents                                   int64\n",
       "tenure                                       int64\n",
       "PhoneService                                 int64\n",
       "MultipleLines                                int64\n",
       "OnlineSecurity                               int64\n",
       "OnlineBackup                                 int64\n",
       "DeviceProtection                             int64\n",
       "TechSupport                                  int64\n",
       "StreamingTV                                  int64\n",
       "StreamingMovies                              int64\n",
       "PaperlessBilling                             int64\n",
       "MonthlyCharges                             float64\n",
       "TotalCharges                               float64\n",
       "Churn                                        int64\n",
       "InternetService_DSL                          int32\n",
       "InternetService_Fiber optic                  int32\n",
       "InternetService_No                           int32\n",
       "Contract_Month-to-month                      int32\n",
       "Contract_One year                            int32\n",
       "Contract_Two year                            int32\n",
       "PaymentMethod_Bank transfer (automatic)      int32\n",
       "PaymentMethod_Credit card (automatic)        int32\n",
       "PaymentMethod_Electronic check               int32\n",
       "PaymentMethod_Mailed check                   int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data types in df2 dataframe, ensure no object-type column (All values under the columns are in number format)\n",
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scaling\n",
    "\n",
    "Ensure all features are on the same scale. Here, all feature values are on the scale between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>...</th>\n",
       "      <th>InternetService_DSL</th>\n",
       "      <th>InternetService_Fiber optic</th>\n",
       "      <th>InternetService_No</th>\n",
       "      <th>Contract_Month-to-month</th>\n",
       "      <th>Contract_One year</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>PaymentMethod_Bank transfer (automatic)</th>\n",
       "      <th>PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>PaymentMethod_Electronic check</th>\n",
       "      <th>PaymentMethod_Mailed check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3593</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.098592</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5131</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.605634</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  SeniorCitizen  Partner  Dependents    tenure  PhoneService  \\\n",
       "3593       0              0        0           0  0.098592             1   \n",
       "5131       1              0        1           0  0.605634             1   \n",
       "1670       0              1        0           1  0.000000             1   \n",
       "\n",
       "      MultipleLines  OnlineSecurity  OnlineBackup  DeviceProtection  ...  \\\n",
       "3593              0               0             0                 0  ...   \n",
       "5131              1               0             0                 0  ...   \n",
       "1670              0               0             0                 1  ...   \n",
       "\n",
       "      InternetService_DSL  InternetService_Fiber optic  InternetService_No  \\\n",
       "3593                    0                            1                   0   \n",
       "5131                    0                            1                   0   \n",
       "1670                    1                            0                   0   \n",
       "\n",
       "      Contract_Month-to-month  Contract_One year  Contract_Two year  \\\n",
       "3593                        1                  0                  0   \n",
       "5131                        1                  0                  0   \n",
       "1670                        1                  0                  0   \n",
       "\n",
       "      PaymentMethod_Bank transfer (automatic)  \\\n",
       "3593                                        0   \n",
       "5131                                        0   \n",
       "1670                                        0   \n",
       "\n",
       "      PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
       "3593                                      0                               0   \n",
       "5131                                      0                               1   \n",
       "1670                                      0                               0   \n",
       "\n",
       "      PaymentMethod_Mailed check  \n",
       "3593                           1  \n",
       "5131                           0  \n",
       "1670                           1  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a variable to store the name of columns required to scale\n",
    "cols_to_scale = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler() # Create a scaler\n",
    "\n",
    "# Scale the values of the column whose name is included in cols_to_scale variable, then update the scaled columns back to the df2 dataframe again.\n",
    "df2[cols_to_scale] = scaler.fit_transform(df2[cols_to_scale])\n",
    "\n",
    "df2.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender: [1 0]\n",
      "SeniorCitizen: [0 1]\n",
      "Partner: [1 0]\n",
      "Dependents: [0 1]\n",
      "tenure: [0.         0.46478873 0.01408451 0.61971831 0.09859155 0.29577465\n",
      " 0.12676056 0.38028169 0.85915493 0.16901408 0.21126761 0.8028169\n",
      " 0.67605634 0.33802817 0.95774648 0.71830986 0.98591549 0.28169014\n",
      " 0.15492958 0.4084507  0.64788732 1.         0.22535211 0.36619718\n",
      " 0.05633803 0.63380282 0.14084507 0.97183099 0.87323944 0.5915493\n",
      " 0.1971831  0.83098592 0.23943662 0.91549296 0.11267606 0.02816901\n",
      " 0.42253521 0.69014085 0.88732394 0.77464789 0.08450704 0.57746479\n",
      " 0.47887324 0.66197183 0.3943662  0.90140845 0.52112676 0.94366197\n",
      " 0.43661972 0.76056338 0.50704225 0.49295775 0.56338028 0.07042254\n",
      " 0.04225352 0.45070423 0.92957746 0.30985915 0.78873239 0.84507042\n",
      " 0.18309859 0.26760563 0.73239437 0.54929577 0.81690141 0.32394366\n",
      " 0.6056338  0.25352113 0.74647887 0.70422535 0.35211268 0.53521127]\n",
      "PhoneService: [0 1]\n",
      "MultipleLines: [0 1]\n",
      "OnlineSecurity: [0 1]\n",
      "OnlineBackup: [1 0]\n",
      "DeviceProtection: [0 1]\n",
      "TechSupport: [0 1]\n",
      "StreamingTV: [0 1]\n",
      "StreamingMovies: [0 1]\n",
      "PaperlessBilling: [1 0]\n",
      "MonthlyCharges: [0.11542289 0.38507463 0.35422886 ... 0.44626866 0.25820896 0.60149254]\n",
      "TotalCharges: [0.0012751  0.21586661 0.01031041 ... 0.03780868 0.03321025 0.78764136]\n",
      "Churn: [0 1]\n",
      "InternetService_DSL: [1 0]\n",
      "InternetService_Fiber optic: [0 1]\n",
      "InternetService_No: [0 1]\n",
      "Contract_Month-to-month: [1 0]\n",
      "Contract_One year: [0 1]\n",
      "Contract_Two year: [0 1]\n",
      "PaymentMethod_Bank transfer (automatic): [0 1]\n",
      "PaymentMethod_Credit card (automatic): [0 1]\n",
      "PaymentMethod_Electronic check: [1 0]\n",
      "PaymentMethod_Mailed check: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Show the unique values of each column/feature in df2 dataframe.\n",
    "for col in df2: \n",
    "    print(f'{col}: {df2[col].unique()}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Spliiting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the features and ground truth of the dataset as separate variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the features of the dataset into X variable\n",
    "X = df2.drop('Churn', axis='columns')\n",
    "\n",
    "# Save the ground truth of the dataset into Y variable\n",
    "Y = df2['Churn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the features and ground truth into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the train set:  5625\n",
      "Number of features of each sample in the train set:  26\n",
      "Number of samples in the test set:  1407\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Spit the features and ground truth into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=5)\n",
    "\n",
    "print('Number of samples in the train set: ', X_train.shape[0])\n",
    "print('Number of features of each sample in the train set: ', X_train.shape[1])\n",
    "print('Number of samples in the test set: ', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample statistics in dataset (overall):\n",
      "Churn\n",
      "0    5163\n",
      "1    1869\n",
      "Name: count, dtype: int64\n",
      "\n",
      "The ratio of samples Class 0 / Class 1 in dataset (overall):  2.7624398073836276\n",
      "\n",
      "Sample statistics in test set:\n",
      "Churn\n",
      "0    999\n",
      "1    408\n",
      "Name: count, dtype: int64\n",
      "\n",
      "The ratio of samples Class 0 / Class 1 in test set:  2.448529411764706\n"
     ]
    }
   ],
   "source": [
    "# The dataset is imbalance (Class 0 [Churn=0, not leaving] has 5163 samples; Class 1 [Churn=1, leaving] has 1869 samples)\n",
    "print('\\nSample statistics in dataset (overall):')\n",
    "print(Y.value_counts())\n",
    "\n",
    "print('\\nThe ratio of samples Class 0 / Class 1 in dataset (overall): ', Y.value_counts()[0]/Y.value_counts()[1])\n",
    "\n",
    "\n",
    "\n",
    "# Hence, the test set is also imbalance (Class 0 [Churn=0, not leaving] has 999 samples; Class 1 [Churn=1, leaving] has 408 samples)\n",
    "print('\\nSample statistics in test set:')\n",
    "print(Y_test.value_counts())\n",
    "print('\\nThe ratio of samples Class 0 / Class 1 in test set: ', Y_test.value_counts()[0]/Y_test.value_counts()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop a neural network (without handling imbalanced dataset)\n",
    "\n",
    "1) The neural network used in this tutorial is Artificial Neural Network (ANN), which consists of only 4 layers (an input layer, 2 hidden layers, and an output layer)\n",
    "2) The F1-score for class 1 (Churn=1, leaving) is low because this dataset is imbalanced (The samples of Churn=0 [Not leaving] is far more than the samples of Churn=1 [leaving])\n",
    "3) Accuracy is useless if your dataset is imbalanced. What is important is to get the F1-score for each class high.\n",
    "4) The goal of this tutorial is handling imbalanced dataset to improve the F1-score for all classes so that the model (neural network) can perform (predict) equally well for samples of all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\weiyo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5914 - loss: 0.6381\n",
      "Epoch 2/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7899 - loss: 0.4373\n",
      "Epoch 3/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7998 - loss: 0.4221\n",
      "Epoch 4/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8108 - loss: 0.4114\n",
      "Epoch 5/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8102 - loss: 0.4105\n",
      "Epoch 6/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8127 - loss: 0.4065\n",
      "Epoch 7/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8128 - loss: 0.4062\n",
      "Epoch 8/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8141 - loss: 0.4012\n",
      "Epoch 9/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8163 - loss: 0.3997\n",
      "Epoch 10/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8063 - loss: 0.4024\n",
      "Epoch 11/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8088 - loss: 0.4129\n",
      "Epoch 12/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8197 - loss: 0.3918\n",
      "Epoch 13/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8130 - loss: 0.4031\n",
      "Epoch 14/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8134 - loss: 0.3923\n",
      "Epoch 15/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8123 - loss: 0.4004\n",
      "Epoch 16/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8234 - loss: 0.3735\n",
      "Epoch 17/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8095 - loss: 0.4043\n",
      "Epoch 18/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8134 - loss: 0.3964\n",
      "Epoch 19/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8099 - loss: 0.3973\n",
      "Epoch 20/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8111 - loss: 0.3929\n",
      "Epoch 21/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8135 - loss: 0.3871\n",
      "Epoch 22/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8219 - loss: 0.3801\n",
      "Epoch 23/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8105 - loss: 0.4016\n",
      "Epoch 24/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8188 - loss: 0.3919\n",
      "Epoch 25/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8217 - loss: 0.3840\n",
      "Epoch 26/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8148 - loss: 0.3927\n",
      "Epoch 27/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8277 - loss: 0.3824\n",
      "Epoch 28/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8207 - loss: 0.3840\n",
      "Epoch 29/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8149 - loss: 0.3875\n",
      "Epoch 30/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8208 - loss: 0.3817\n",
      "Epoch 31/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8152 - loss: 0.3874\n",
      "Epoch 32/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8193 - loss: 0.3793\n",
      "Epoch 33/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8231 - loss: 0.3766\n",
      "Epoch 34/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8102 - loss: 0.3929\n",
      "Epoch 35/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8220 - loss: 0.3803\n",
      "Epoch 36/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8265 - loss: 0.3766\n",
      "Epoch 37/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8245 - loss: 0.3817\n",
      "Epoch 38/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8256 - loss: 0.3720\n",
      "Epoch 39/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8154 - loss: 0.3927\n",
      "Epoch 40/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8270 - loss: 0.3745\n",
      "Epoch 41/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8218 - loss: 0.3754\n",
      "Epoch 42/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8281 - loss: 0.3770\n",
      "Epoch 43/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8185 - loss: 0.3869\n",
      "Epoch 44/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8233 - loss: 0.3851\n",
      "Epoch 45/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8284 - loss: 0.3681\n",
      "Epoch 46/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8222 - loss: 0.3829\n",
      "Epoch 47/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8173 - loss: 0.3865\n",
      "Epoch 48/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8232 - loss: 0.3722\n",
      "Epoch 49/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8271 - loss: 0.3792\n",
      "Epoch 50/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8254 - loss: 0.3645\n",
      "Epoch 51/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8286 - loss: 0.3729\n",
      "Epoch 52/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8334 - loss: 0.3656\n",
      "Epoch 53/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8330 - loss: 0.3670\n",
      "Epoch 54/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8251 - loss: 0.3719\n",
      "Epoch 55/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8285 - loss: 0.3678\n",
      "Epoch 56/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8293 - loss: 0.3660\n",
      "Epoch 57/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8263 - loss: 0.3783\n",
      "Epoch 58/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8297 - loss: 0.3646\n",
      "Epoch 59/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8279 - loss: 0.3677\n",
      "Epoch 60/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8283 - loss: 0.3715\n",
      "Epoch 61/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8315 - loss: 0.3769\n",
      "Epoch 62/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8277 - loss: 0.3627\n",
      "Epoch 63/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8293 - loss: 0.3662\n",
      "Epoch 64/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8356 - loss: 0.3594\n",
      "Epoch 65/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8262 - loss: 0.3701\n",
      "Epoch 66/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8338 - loss: 0.3560\n",
      "Epoch 67/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8374 - loss: 0.3600\n",
      "Epoch 68/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8409 - loss: 0.3592\n",
      "Epoch 69/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8393 - loss: 0.3593\n",
      "Epoch 70/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8320 - loss: 0.3615\n",
      "Epoch 71/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8363 - loss: 0.3502\n",
      "Epoch 72/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8321 - loss: 0.3629\n",
      "Epoch 73/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8331 - loss: 0.3663\n",
      "Epoch 74/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8305 - loss: 0.3766\n",
      "Epoch 75/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8320 - loss: 0.3613\n",
      "Epoch 76/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8338 - loss: 0.3639\n",
      "Epoch 77/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8333 - loss: 0.3518\n",
      "Epoch 78/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8276 - loss: 0.3678\n",
      "Epoch 79/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8286 - loss: 0.3765\n",
      "Epoch 80/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8420 - loss: 0.3526\n",
      "Epoch 81/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8380 - loss: 0.3467\n",
      "Epoch 82/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.8400 - loss: 0.3520\n",
      "Epoch 83/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8325 - loss: 0.3643\n",
      "Epoch 84/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8263 - loss: 0.3733\n",
      "Epoch 85/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8322 - loss: 0.3627\n",
      "Epoch 86/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.8328 - loss: 0.3645\n",
      "Epoch 87/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8413 - loss: 0.3494\n",
      "Epoch 88/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8297 - loss: 0.3648\n",
      "Epoch 89/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8419 - loss: 0.3513\n",
      "Epoch 90/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8266 - loss: 0.3575\n",
      "Epoch 91/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8341 - loss: 0.3600\n",
      "Epoch 92/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8336 - loss: 0.3575\n",
      "Epoch 93/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8341 - loss: 0.3676\n",
      "Epoch 94/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8386 - loss: 0.3477\n",
      "Epoch 95/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8364 - loss: 0.3627\n",
      "Epoch 96/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8385 - loss: 0.3457\n",
      "Epoch 97/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8474 - loss: 0.3371\n",
      "Epoch 98/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8422 - loss: 0.3465\n",
      "Epoch 99/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8322 - loss: 0.3525\n",
      "Epoch 100/100\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8394 - loss: 0.3457\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.7737 - loss: 0.4699\n",
      "[0.4751972556114197, 0.7697228193283081]\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84       999\n",
      "           1       0.63      0.51      0.56       408\n",
      "\n",
      "    accuracy                           0.77      1407\n",
      "   macro avg       0.72      0.69      0.70      1407\n",
      "weighted avg       0.76      0.77      0.76      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Self-define a function to create the structure of a neural network, compile the model, evaluate the model using test set, print the classification report and prints the rounded predicted results\n",
    "def ANN(X_train, Y_train, X_test, Y_test, loss, weights):\n",
    "    # Create the structure of the neural network\n",
    "    model = keras.Sequential([\n",
    "        # The hidden layer (the 2nd layer), which consists of 26 neurons, with ReLU as the activation function. Before this layer is the input layer (the 1st layer, of shape/consists 26 input neurons) which receive 26 features from the train set. \n",
    "        keras.layers.Dense(20, input_shape = (26,), activation='relu'),\n",
    "        # The hidden layer (the 3rd layer), which consists of 15 neurons, with ReLU as the activation function.\n",
    "        keras.layers.Dense(20, input_shape = (15,), activation='relu'),\n",
    "        # The output layer (the 4th layer), which consists of 1 output neuron (to provide score if the customer churn) with sigmoid function as the activation function.\n",
    "        keras.layers.Dense(1, activation = 'sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Compile the neural network\n",
    "    model.compile(optimizer = 'adam',\n",
    "                loss = loss, \n",
    "                metrics = ['accuracy'])\n",
    "\n",
    "    if weights == -1:\n",
    "        model.fit(X_train, Y_train, epochs = 100)\n",
    "    else:\n",
    "        model.fit(X_train, Y_train, epochs = 100, class_weight = weights)\n",
    "\n",
    "    # Evaluate the model using test set\n",
    "    print(model.evaluate(X_test, Y_test))\n",
    "\n",
    "    # Use the model to make prediction over the samples in test set\n",
    "    Y_predicted = model.predict(X_test)\n",
    "    # Round the predicted results\n",
    "    Y_predicted_rounded = np.round(Y_predicted)\n",
    "\n",
    "    # Print the classification report\n",
    "    print('Classification Report:\\n', classification_report(Y_test, Y_predicted_rounded))\n",
    "\n",
    "    # Return the rounded predicted results\n",
    "    return Y_predicted_rounded\n",
    "\n",
    "# Get the rounded predicted results over the samples in test set\n",
    "Y_predicted_rounded = ANN(X_train, Y_train, X_test, Y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technique to handle imbalanced dataset\n",
    "\n",
    "You have to try different methods to handle imbalanced dataset to identify which method works the best for your scenario (dataset), because in machine learning there is no guarantee a method can work best for a scenario without trying all alternative methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Undersampling\n",
    "\n",
    "Let's say in test set, number samples of Class 0 = j while number samples of Class 1 = k, where j>k. We only takes k number of Class 0 samples and k number of Class 1 samples to concatenate together then split them into train and test set before using them to train the model\n",
    "\n",
    "<img src=\"hidden\\undersampling.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 400px;\"/>  <br /><br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Class 0 samples in total:  5163\n",
      "Number of Class 1 samples in total:  1869\n",
      "The df_class_0 dataframe (that only contains Class 0 samples) consists of 5163 samples, while each sample consists of 27 features.\n",
      "The df_class_1 dataframe (that only contains Class 1 samples) consists of 1869 samples, while each sample consists of 27 features.\n"
     ]
    }
   ],
   "source": [
    "# Count the samples of different classes in df1 dataframe\n",
    "count_class_0, count_class_1 = df1.Churn.value_counts()\n",
    "print('Number of Class 0 samples in total: ', count_class_0)\n",
    "print('Number of Class 1 samples in total: ', count_class_1)\n",
    "\n",
    "# Divide by class\n",
    "# Save only Class 0 samples to a new dataframe called df_class_0\n",
    "df_class_0 = df2[df2['Churn']==0]\n",
    "# Save only Class 1 samples to a new dataframe called df_class_1\n",
    "df_class_1 = df2[df2['Churn']==1]\n",
    "\n",
    "print('The df_class_0 dataframe (that only contains Class 0 samples) consists of ' + str(df_class_0.shape[0]) + ' samples, while each sample consists of ' + str(df_class_0.shape[1]) + ' features.')\n",
    "print('The df_class_1 dataframe (that only contains Class 1 samples) consists of ' + str(df_class_1.shape[0]) + ' samples, while each sample consists of ' + str(df_class_1.shape[1]) + ' features.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The df_undersampling dataframe (that contains undersampled Class 0 samples & all Class 1 samples) consists of 3738 samples, while each sample consists of 27 features.\n",
      "\n",
      "Random undersampling:\n",
      " Churn\n",
      "0    1869\n",
      "1    1869\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Randomly select count_class_1 number (random undersampling) of Class 0 samples in df_class_0 dataframe, then store them into a new dataframe called df_class_0_undersampled\n",
    "df_class_0_undersampled = df_class_0.sample(count_class_1)\n",
    "\n",
    "# Concatenate all samples in df_class_0_undersampled dataframe & all samples in df_class_1 dataframe in rows, then save them into a new dataframe called df_undersampling\n",
    "df_undersampling = pd.concat([df_class_0_undersampled,df_class_1], axis=0)\n",
    "\n",
    "print('The df_undersampling dataframe (that contains undersampled Class 0 samples & all Class 1 samples) consists of ' + str(df_undersampling.shape[0]) + ' samples, while each sample consists of ' + str(df_undersampling.shape[1]) + ' features.')\n",
    "\n",
    "# Verify after random undersampling, both classes have same number of samples\n",
    "print('\\nRandom undersampling:\\n', df_undersampling.Churn.value_counts()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the undersampled dataset into features and ground truths variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_undersampling = df_undersampling.drop('Churn', axis='columns')\n",
    "Y_undersampling = df_undersampling['Churn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the features and ground truths variables into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampled train set samples statistics:\n",
      " Churn\n",
      "0    1495\n",
      "1    1495\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Undersampled test set samples statistics:\n",
      " Churn\n",
      "1    374\n",
      "0    374\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# stratify takes the ground truths variable as input to ensure the samples of different classes in train and test sets are balanced (based on the ratio of the samples of different classes in ground truths variable)\n",
    "X_train_undersampling, X_test_undersampling, Y_train_undersampling, Y_test_undersampling = train_test_split(X_undersampling, Y_undersampling, test_size=0.2, random_state=15, stratify=Y_undersampling)\n",
    "\n",
    "print('Undersampled train set samples statistics:\\n', Y_train_undersampling.value_counts()) \n",
    "print('\\nUndersampled test set samples statistics:\\n', Y_test_undersampling.value_counts()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get prediction results over samples in undersampled test set using ANN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\weiyo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6671 - loss: 0.6316\n",
      "Epoch 2/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7333 - loss: 0.5302\n",
      "Epoch 3/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7497 - loss: 0.5080\n",
      "Epoch 4/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7569 - loss: 0.4977\n",
      "Epoch 5/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7615 - loss: 0.4910\n",
      "Epoch 6/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7562 - loss: 0.4911\n",
      "Epoch 7/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7556 - loss: 0.4935\n",
      "Epoch 8/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7515 - loss: 0.5099\n",
      "Epoch 9/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7723 - loss: 0.4773\n",
      "Epoch 10/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7584 - loss: 0.4827\n",
      "Epoch 11/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7523 - loss: 0.4939\n",
      "Epoch 12/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7759 - loss: 0.4784\n",
      "Epoch 13/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7738 - loss: 0.4741\n",
      "Epoch 14/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7602 - loss: 0.4882\n",
      "Epoch 15/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7622 - loss: 0.4840\n",
      "Epoch 16/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7467 - loss: 0.4964\n",
      "Epoch 17/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7796 - loss: 0.4697\n",
      "Epoch 18/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7677 - loss: 0.4745\n",
      "Epoch 19/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7592 - loss: 0.4764\n",
      "Epoch 20/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7653 - loss: 0.4767\n",
      "Epoch 21/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7558 - loss: 0.4929\n",
      "Epoch 22/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7491 - loss: 0.5054\n",
      "Epoch 23/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7766 - loss: 0.4650\n",
      "Epoch 24/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7629 - loss: 0.4817\n",
      "Epoch 25/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7673 - loss: 0.4754\n",
      "Epoch 26/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7626 - loss: 0.4741\n",
      "Epoch 27/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7672 - loss: 0.4705\n",
      "Epoch 28/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7599 - loss: 0.4767\n",
      "Epoch 29/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7609 - loss: 0.4744\n",
      "Epoch 30/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7722 - loss: 0.4663\n",
      "Epoch 31/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7581 - loss: 0.4790\n",
      "Epoch 32/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7780 - loss: 0.4699\n",
      "Epoch 33/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7723 - loss: 0.4736\n",
      "Epoch 34/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7707 - loss: 0.4559\n",
      "Epoch 35/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7701 - loss: 0.4651\n",
      "Epoch 36/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7670 - loss: 0.4734\n",
      "Epoch 37/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7766 - loss: 0.4653\n",
      "Epoch 38/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7781 - loss: 0.4600\n",
      "Epoch 39/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7890 - loss: 0.4549\n",
      "Epoch 40/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7676 - loss: 0.4734\n",
      "Epoch 41/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7890 - loss: 0.4583\n",
      "Epoch 42/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7936 - loss: 0.4524\n",
      "Epoch 43/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7936 - loss: 0.4469\n",
      "Epoch 44/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7677 - loss: 0.4757\n",
      "Epoch 45/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7768 - loss: 0.4677\n",
      "Epoch 46/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7843 - loss: 0.4599\n",
      "Epoch 47/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7821 - loss: 0.4565\n",
      "Epoch 48/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7884 - loss: 0.4564\n",
      "Epoch 49/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7968 - loss: 0.4507\n",
      "Epoch 50/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7986 - loss: 0.4429\n",
      "Epoch 51/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7815 - loss: 0.4733\n",
      "Epoch 52/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7882 - loss: 0.4558\n",
      "Epoch 53/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7802 - loss: 0.4594\n",
      "Epoch 54/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7870 - loss: 0.4599\n",
      "Epoch 55/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7857 - loss: 0.4573\n",
      "Epoch 56/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7890 - loss: 0.4520\n",
      "Epoch 57/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7941 - loss: 0.4502\n",
      "Epoch 58/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7890 - loss: 0.4521\n",
      "Epoch 59/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7956 - loss: 0.4337\n",
      "Epoch 60/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7981 - loss: 0.4389\n",
      "Epoch 61/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7868 - loss: 0.4563\n",
      "Epoch 62/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7857 - loss: 0.4558\n",
      "Epoch 63/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7999 - loss: 0.4410\n",
      "Epoch 64/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7985 - loss: 0.4347\n",
      "Epoch 65/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7934 - loss: 0.4521\n",
      "Epoch 66/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7895 - loss: 0.4475\n",
      "Epoch 67/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7969 - loss: 0.4443\n",
      "Epoch 68/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7899 - loss: 0.4507\n",
      "Epoch 69/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7938 - loss: 0.4521\n",
      "Epoch 70/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8118 - loss: 0.4274\n",
      "Epoch 71/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7858 - loss: 0.4482\n",
      "Epoch 72/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7959 - loss: 0.4373\n",
      "Epoch 73/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7981 - loss: 0.4345\n",
      "Epoch 74/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8042 - loss: 0.4200\n",
      "Epoch 75/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7928 - loss: 0.4448\n",
      "Epoch 76/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7991 - loss: 0.4357\n",
      "Epoch 77/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7890 - loss: 0.4449\n",
      "Epoch 78/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7973 - loss: 0.4257\n",
      "Epoch 79/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8018 - loss: 0.4274\n",
      "Epoch 80/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7963 - loss: 0.4333\n",
      "Epoch 81/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8031 - loss: 0.4249\n",
      "Epoch 82/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8018 - loss: 0.4236\n",
      "Epoch 83/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7898 - loss: 0.4441\n",
      "Epoch 84/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7983 - loss: 0.4316\n",
      "Epoch 85/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7959 - loss: 0.4278\n",
      "Epoch 86/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8126 - loss: 0.4191\n",
      "Epoch 87/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7982 - loss: 0.4338\n",
      "Epoch 88/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7998 - loss: 0.4387\n",
      "Epoch 89/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8030 - loss: 0.4182\n",
      "Epoch 90/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8068 - loss: 0.4270\n",
      "Epoch 91/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7980 - loss: 0.4302\n",
      "Epoch 92/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7966 - loss: 0.4199\n",
      "Epoch 93/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8100 - loss: 0.4235\n",
      "Epoch 94/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7981 - loss: 0.4332\n",
      "Epoch 95/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8100 - loss: 0.4194\n",
      "Epoch 96/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8029 - loss: 0.4171\n",
      "Epoch 97/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8111 - loss: 0.4187\n",
      "Epoch 98/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8059 - loss: 0.4158\n",
      "Epoch 99/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7927 - loss: 0.4295\n",
      "Epoch 100/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8014 - loss: 0.4282\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7360 - loss: 0.5442  \n",
      "[0.5458436012268066, 0.7245989441871643]\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72       374\n",
      "           1       0.71      0.75      0.73       374\n",
      "\n",
      "    accuracy                           0.72       748\n",
      "   macro avg       0.73      0.72      0.72       748\n",
      "weighted avg       0.73      0.72      0.72       748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_predicted_rounded_undersampling = ANN(X_train_undersampling, Y_train_undersampling, X_test_undersampling, Y_test_undersampling, 'binary_crossentropy', -1)\n",
    "\n",
    "# Insights: \n",
    "# The results show that when imbalanced dataset is handled using undersampling technique, the precision, recall and F1-score for Class 1 (minority class) samples are improved, but the precision, recall and F1-score for Class 0 (majority class) samples decreased, compared to the results obtained when imbalanced dataset is not handled. \n",
    "# But that's ok, because now you are doing fair treatment for minority class and majority class (the model now performs(predicts) equally well for samples of all classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Oversampling (by duplication)\n",
    "\n",
    "Let's say in test set, number samples of Class 0 = j while number samples of Class 1 = k, where j>k. We increase the number of Class 1 samples to k (so that number of Class 0 and Class 1 samples are now same). Then, concatenate the Class 0 samples and oversampled Class 1 samples to together then split them into train and test set before using them to train the model\n",
    "\n",
    "<img src=\"hidden\\oversampling.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 400px;\"/>  <br /><br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The df_class_0 dataframe (that only contains Class 0 samples) consists of 5163 samples, while each sample consists of 27 features.\n",
      "The df_class_1 dataframe (that only contains Class 1 samples) consists of 1869 samples, while each sample consists of 27 features.\n",
      "The df_class_1_oversampled dataframe (that only contains Class 1 samples) consists of 5163 samples, while each sample consists of 27 features.\n",
      "The df_oversampling dataframe (that contains all Class 0 samples & oversampled Class 1 samples) consists of 10326 samples, while each sample consists of 27 features.\n",
      "\n",
      "Random oversampling:\n",
      " Churn\n",
      "0    5163\n",
      "1    5163\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('The df_class_0 dataframe (that only contains Class 0 samples) consists of ' + str(df_class_0.shape[0]) + ' samples, while each sample consists of ' + str(df_class_0.shape[1]) + ' features.')\n",
    "print('The df_class_1 dataframe (that only contains Class 1 samples) consists of ' + str(df_class_1.shape[0]) + ' samples, while each sample consists of ' + str(df_class_1.shape[1]) + ' features.')\n",
    "\n",
    "# Increase the number of samples in df_class_1 dataframe such that the number of samples in df_class_1 & df_class_0 are same.\n",
    "# To increase the number of samples in df_class_1 dataframe, the original count_class_1 number of samples in df_class_1 are remained, but count_class_0 - count_class_1 = 131 samples are synthesized(generated) by randomly select the samples in df_class_1 dataframe and just copy & paste (duplicate) them (because replace=True) back to the same dataframe again.\n",
    "# The updated oversampled df_class_1 dataframe is saved to a new dataframe called df_class_1_oversampled\n",
    "df_class_1_oversampled = df_class_1.sample(count_class_0, replace=True)\n",
    "\n",
    "print('The df_class_1_oversampled dataframe (that only contains Class 1 samples) consists of ' + str(df_class_1_oversampled.shape[0]) + ' samples, while each sample consists of ' + str(df_class_1_oversampled.shape[1]) + ' features.')\n",
    "\n",
    "# Concatenate all samples in df_class_0 dataframe & all samples in df_class_1_oversampled dataframe in rows, then save them into a new dataframe called df_oversampling\n",
    "df_oversampling = pd.concat([df_class_0,df_class_1_oversampled], axis=0)\n",
    "\n",
    "print('The df_oversampling dataframe (that contains all Class 0 samples & oversampled Class 1 samples) consists of ' + str(df_oversampling.shape[0]) + ' samples, while each sample consists of ' + str(df_oversampling.shape[1]) + ' features.')\n",
    "\n",
    "# Verify after random oversampling, both classes have same number of samples\n",
    "print('\\nRandom oversampling:\\n', df_oversampling.Churn.value_counts()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the oversampled dataset into features and ground truths variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_oversampling = df_oversampling.drop('Churn', axis='columns')\n",
    "Y_oversampling = df_oversampling['Churn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the features and ground truths variables into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampled train set samples statistics:\n",
      " Churn\n",
      "1    4130\n",
      "0    4130\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Undersampled test set samples statistics:\n",
      " Churn\n",
      "1    1033\n",
      "0    1033\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# stratify takes the ground truths variable as input to ensure the samples of different classes in train and test sets are balanced [class distribution is equal] (based on the ratio of the samples of different classes in ground truths variable)\n",
    "X_train_oversampling, X_test_oversampling, Y_train_oversampling, Y_test_oversampling = train_test_split(X_oversampling, Y_oversampling, test_size=0.2, random_state=15, stratify=Y_oversampling)\n",
    "\n",
    "print('Oversampled train set samples statistics:\\n', Y_train_oversampling.value_counts()) \n",
    "print('\\nOversampled test set samples statistics:\\n', Y_test_oversampling.value_counts()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get prediction results over samples in oversampled test set using ANN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\weiyo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6891 - loss: 0.6095\n",
      "Epoch 2/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7491 - loss: 0.5091\n",
      "Epoch 3/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7650 - loss: 0.4770\n",
      "Epoch 4/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7645 - loss: 0.4869\n",
      "Epoch 5/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7780 - loss: 0.4709\n",
      "Epoch 6/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7772 - loss: 0.4702\n",
      "Epoch 7/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7680 - loss: 0.4693\n",
      "Epoch 8/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7763 - loss: 0.4708\n",
      "Epoch 9/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7677 - loss: 0.4768\n",
      "Epoch 10/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7780 - loss: 0.4754\n",
      "Epoch 11/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7865 - loss: 0.4564\n",
      "Epoch 12/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7810 - loss: 0.4613\n",
      "Epoch 13/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7773 - loss: 0.4708\n",
      "Epoch 14/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7918 - loss: 0.4537\n",
      "Epoch 15/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7899 - loss: 0.4554\n",
      "Epoch 16/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7876 - loss: 0.4506\n",
      "Epoch 17/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7919 - loss: 0.4477\n",
      "Epoch 18/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7912 - loss: 0.4439\n",
      "Epoch 19/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7902 - loss: 0.4478\n",
      "Epoch 20/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7873 - loss: 0.4456\n",
      "Epoch 21/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7878 - loss: 0.4453\n",
      "Epoch 22/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7956 - loss: 0.4401\n",
      "Epoch 23/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7871 - loss: 0.4408\n",
      "Epoch 24/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7956 - loss: 0.4432\n",
      "Epoch 25/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7949 - loss: 0.4366\n",
      "Epoch 26/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7938 - loss: 0.4382\n",
      "Epoch 27/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7985 - loss: 0.4264\n",
      "Epoch 28/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7900 - loss: 0.4422\n",
      "Epoch 29/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8010 - loss: 0.4259\n",
      "Epoch 30/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7946 - loss: 0.4313\n",
      "Epoch 31/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7914 - loss: 0.4365\n",
      "Epoch 32/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7933 - loss: 0.4379\n",
      "Epoch 33/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8045 - loss: 0.4241\n",
      "Epoch 34/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8013 - loss: 0.4219\n",
      "Epoch 35/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8039 - loss: 0.4243\n",
      "Epoch 36/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8033 - loss: 0.4252\n",
      "Epoch 37/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7956 - loss: 0.4286\n",
      "Epoch 38/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8043 - loss: 0.4161\n",
      "Epoch 39/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7995 - loss: 0.4244\n",
      "Epoch 40/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8043 - loss: 0.4319\n",
      "Epoch 41/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8107 - loss: 0.4150\n",
      "Epoch 42/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7975 - loss: 0.4127\n",
      "Epoch 43/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8035 - loss: 0.4150\n",
      "Epoch 44/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7991 - loss: 0.4278\n",
      "Epoch 45/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8022 - loss: 0.4231\n",
      "Epoch 46/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8078 - loss: 0.4102\n",
      "Epoch 47/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8086 - loss: 0.4121\n",
      "Epoch 48/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8016 - loss: 0.4196\n",
      "Epoch 49/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8054 - loss: 0.4129\n",
      "Epoch 50/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8066 - loss: 0.4113\n",
      "Epoch 51/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8063 - loss: 0.4143\n",
      "Epoch 52/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8090 - loss: 0.4068\n",
      "Epoch 53/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8090 - loss: 0.4141\n",
      "Epoch 54/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8123 - loss: 0.4088\n",
      "Epoch 55/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8090 - loss: 0.4054\n",
      "Epoch 56/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8131 - loss: 0.4032\n",
      "Epoch 57/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8177 - loss: 0.4034\n",
      "Epoch 58/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8101 - loss: 0.4053\n",
      "Epoch 59/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8003 - loss: 0.4119\n",
      "Epoch 60/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8236 - loss: 0.3907\n",
      "Epoch 61/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8118 - loss: 0.4076\n",
      "Epoch 62/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8146 - loss: 0.4028\n",
      "Epoch 63/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8141 - loss: 0.4101\n",
      "Epoch 64/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8187 - loss: 0.3919\n",
      "Epoch 65/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8239 - loss: 0.3948\n",
      "Epoch 66/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8152 - loss: 0.4010\n",
      "Epoch 67/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8187 - loss: 0.3925\n",
      "Epoch 68/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8263 - loss: 0.3915\n",
      "Epoch 69/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8129 - loss: 0.3947\n",
      "Epoch 70/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8179 - loss: 0.3946\n",
      "Epoch 71/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8213 - loss: 0.3933\n",
      "Epoch 72/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8109 - loss: 0.4076\n",
      "Epoch 73/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8197 - loss: 0.3934\n",
      "Epoch 74/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8132 - loss: 0.4051\n",
      "Epoch 75/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8212 - loss: 0.3905\n",
      "Epoch 76/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8226 - loss: 0.3822\n",
      "Epoch 77/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8095 - loss: 0.4059\n",
      "Epoch 78/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8225 - loss: 0.3896\n",
      "Epoch 79/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8143 - loss: 0.3934\n",
      "Epoch 80/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8210 - loss: 0.3915\n",
      "Epoch 81/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8209 - loss: 0.3857\n",
      "Epoch 82/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8199 - loss: 0.3900\n",
      "Epoch 83/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8157 - loss: 0.3906\n",
      "Epoch 84/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8095 - loss: 0.4038\n",
      "Epoch 85/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8218 - loss: 0.3925\n",
      "Epoch 86/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8210 - loss: 0.3936\n",
      "Epoch 87/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8217 - loss: 0.3895\n",
      "Epoch 88/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8222 - loss: 0.3934\n",
      "Epoch 89/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8270 - loss: 0.3800\n",
      "Epoch 90/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8251 - loss: 0.3789\n",
      "Epoch 91/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8245 - loss: 0.3805\n",
      "Epoch 92/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8217 - loss: 0.3807\n",
      "Epoch 93/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8302 - loss: 0.3752\n",
      "Epoch 94/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8296 - loss: 0.3768\n",
      "Epoch 95/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8250 - loss: 0.3842\n",
      "Epoch 96/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8307 - loss: 0.3716\n",
      "Epoch 97/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8250 - loss: 0.3828\n",
      "Epoch 98/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8280 - loss: 0.3758\n",
      "Epoch 99/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8233 - loss: 0.3782\n",
      "Epoch 100/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8293 - loss: 0.3770\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - accuracy: 0.8024 - loss: 0.4370\n",
      "[0.4550453722476959, 0.7952565550804138]\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.71      0.78      1033\n",
      "           1       0.75      0.88      0.81      1033\n",
      "\n",
      "    accuracy                           0.80      2066\n",
      "   macro avg       0.80      0.80      0.79      2066\n",
      "weighted avg       0.80      0.80      0.79      2066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_predicted_rounded_oversampling = ANN(X_train_oversampling, Y_train_oversampling, X_test_oversampling, Y_test_oversampling, 'binary_crossentropy', -1)\n",
    "\n",
    "# Insights: \n",
    "# 1) The results show that when imbalanced dataset is handled using oversampling technique, the precision, recall and F1-score for Class 1 (minority class) samples are improved, but the precision, recall and F1-score for Class 0 (majority class) samples decreased, compared to the results obtained when imbalanced dataset is not handled. \n",
    "# But that's ok, because now you are doing fair treatment for minority class and majority class (the model now performs(predicts) equally well for samples of all classes)\n",
    "# 2) According here, when imbalanced dataset is handled using oversampling technique, the precision, recall and F1-score for Class 1 (minority class) samples are improved better, compared to the ones using undersampling technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: Synthetic Minority Over-sampling Technique (SMOTE)\n",
    "\n",
    "SMOTE is better than oversampling technique (Method 2) because SMOTE increases the samples of minority class through creating new samples out of the current samples of minority class using K nearest neighbours algorithm\n",
    "\n",
    "<img src=\"hidden\\smote.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 400px;\"/>  <br /><br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample statistics in dataset (overall):\n",
      "Churn\n",
      "0    5163\n",
      "1    1869\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Save the features of the dataset into X variable\n",
    "X = df2.drop('Churn', axis='columns')\n",
    "\n",
    "# Save the ground truth of the dataset into Y variable\n",
    "Y = df2['Churn']\n",
    "\n",
    "# The dataset is imbalance (Class 0 [Churn=0, not leaving] has 5163 samples; Class 1 [Churn=1, leaving] has 1869 samples)\n",
    "print('\\nSample statistics in dataset (overall):')\n",
    "print(Y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SMOTE oversampling:\n",
      " Churn\n",
      "0    5163\n",
      "1    5163\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Create an object of SMOTE class caleed smote. sampling_strategy='minority' so that SMOTE will increase the samples of minority class (the class that has fewer samples compared to other class)\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "\n",
    "# After SMOTE learn the minority class samples in X & Y (the input), it generates new samples using K nearest neighbours technique (without just copy & paste the existing minority class samples). The existing samples and new generated samples are saved to a dataframe, then the features of the dataframe are saved to X_SMOTE dataframe, while the ground truths are saved to Y_SMOTE\n",
    "X_oversampling_SMOTE, Y_oversampling_SMOTE = smote.fit_resample(X, Y)\n",
    "\n",
    "# Verify after SMOTE oversampling, both classes have same number of samples\n",
    "print('\\nSMOTE oversampling:\\n', Y_oversampling_SMOTE.value_counts()) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the features and ground truths variables into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE oversampled train set samples statistics:\n",
      " Churn\n",
      "1    4130\n",
      "0    4130\n",
      "Name: count, dtype: int64\n",
      "\n",
      "SMOTE oversampled test set samples statistics:\n",
      " Churn\n",
      "1    1033\n",
      "0    1033\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# stratify takes the ground truths variable as input to ensure the samples of different classes in train and test sets are balanced [class distribution is equal] (based on the ratio of the samples of different classes in ground truths variable)\n",
    "X_train_oversampling_SMOTE, X_test_oversampling_SMOTE, Y_train_oversampling_SMOTE, Y_test_oversampling_SMOTE = train_test_split(X_oversampling_SMOTE, Y_oversampling_SMOTE, test_size=0.2, random_state=15, stratify=Y_oversampling_SMOTE)\n",
    "\n",
    "print('SMOTE oversampled train set samples statistics:\\n', Y_train_oversampling_SMOTE.value_counts()) \n",
    "print('\\nSMOTE oversampled test set samples statistics:\\n', Y_test_oversampling_SMOTE.value_counts()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get prediction results over samples in SMOTE oversampled test set using ANN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\weiyo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6687 - loss: 0.6160\n",
      "Epoch 2/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7772 - loss: 0.4676\n",
      "Epoch 3/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7821 - loss: 0.4672\n",
      "Epoch 4/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7829 - loss: 0.4577\n",
      "Epoch 5/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7923 - loss: 0.4458\n",
      "Epoch 6/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7868 - loss: 0.4559\n",
      "Epoch 7/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7844 - loss: 0.4535\n",
      "Epoch 8/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8011 - loss: 0.4367\n",
      "Epoch 9/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7961 - loss: 0.4446\n",
      "Epoch 10/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8042 - loss: 0.4276\n",
      "Epoch 11/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7990 - loss: 0.4352\n",
      "Epoch 12/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8050 - loss: 0.4265\n",
      "Epoch 13/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8033 - loss: 0.4183\n",
      "Epoch 14/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8079 - loss: 0.4214\n",
      "Epoch 15/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8031 - loss: 0.4246\n",
      "Epoch 16/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8068 - loss: 0.4225\n",
      "Epoch 17/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8049 - loss: 0.4219\n",
      "Epoch 18/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8108 - loss: 0.4146\n",
      "Epoch 19/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8032 - loss: 0.4181\n",
      "Epoch 20/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8139 - loss: 0.4152\n",
      "Epoch 21/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8103 - loss: 0.4106\n",
      "Epoch 22/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8175 - loss: 0.4003\n",
      "Epoch 23/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8047 - loss: 0.4287\n",
      "Epoch 24/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8116 - loss: 0.4123\n",
      "Epoch 25/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8197 - loss: 0.4026\n",
      "Epoch 26/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8185 - loss: 0.3935\n",
      "Epoch 27/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8219 - loss: 0.3989\n",
      "Epoch 28/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8170 - loss: 0.4032\n",
      "Epoch 29/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8208 - loss: 0.3982\n",
      "Epoch 30/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8318 - loss: 0.3852\n",
      "Epoch 31/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8253 - loss: 0.3962\n",
      "Epoch 32/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8288 - loss: 0.3873\n",
      "Epoch 33/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8210 - loss: 0.3992\n",
      "Epoch 34/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8271 - loss: 0.3902\n",
      "Epoch 35/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8277 - loss: 0.3783\n",
      "Epoch 36/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8315 - loss: 0.3783\n",
      "Epoch 37/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8286 - loss: 0.3813\n",
      "Epoch 38/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8304 - loss: 0.3791\n",
      "Epoch 39/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8316 - loss: 0.3791\n",
      "Epoch 40/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8296 - loss: 0.3844\n",
      "Epoch 41/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8296 - loss: 0.3783\n",
      "Epoch 42/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8353 - loss: 0.3765\n",
      "Epoch 43/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8315 - loss: 0.3766\n",
      "Epoch 44/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8335 - loss: 0.3822\n",
      "Epoch 45/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8292 - loss: 0.3765\n",
      "Epoch 46/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8429 - loss: 0.3684\n",
      "Epoch 47/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8306 - loss: 0.3702\n",
      "Epoch 48/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8419 - loss: 0.3612\n",
      "Epoch 49/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8375 - loss: 0.3721\n",
      "Epoch 50/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8318 - loss: 0.3749\n",
      "Epoch 51/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8406 - loss: 0.3703\n",
      "Epoch 52/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8386 - loss: 0.3723\n",
      "Epoch 53/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8372 - loss: 0.3650\n",
      "Epoch 54/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8371 - loss: 0.3659\n",
      "Epoch 55/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8397 - loss: 0.3699\n",
      "Epoch 56/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8387 - loss: 0.3639\n",
      "Epoch 57/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8349 - loss: 0.3684\n",
      "Epoch 58/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8399 - loss: 0.3652\n",
      "Epoch 59/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8420 - loss: 0.3586\n",
      "Epoch 60/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8376 - loss: 0.3637\n",
      "Epoch 61/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8391 - loss: 0.3676\n",
      "Epoch 62/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3621\n",
      "Epoch 63/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8429 - loss: 0.3630\n",
      "Epoch 64/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8421 - loss: 0.3610\n",
      "Epoch 65/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8439 - loss: 0.3556\n",
      "Epoch 66/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8417 - loss: 0.3549\n",
      "Epoch 67/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8497 - loss: 0.3525\n",
      "Epoch 68/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8480 - loss: 0.3563\n",
      "Epoch 69/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8447 - loss: 0.3553\n",
      "Epoch 70/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8443 - loss: 0.3539\n",
      "Epoch 71/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8418 - loss: 0.3614\n",
      "Epoch 72/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8512 - loss: 0.3446\n",
      "Epoch 73/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8458 - loss: 0.3510\n",
      "Epoch 74/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8385 - loss: 0.3629\n",
      "Epoch 75/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8484 - loss: 0.3436\n",
      "Epoch 76/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8500 - loss: 0.3458\n",
      "Epoch 77/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8498 - loss: 0.3486\n",
      "Epoch 78/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8477 - loss: 0.3518\n",
      "Epoch 79/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8463 - loss: 0.3511\n",
      "Epoch 80/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8429 - loss: 0.3581\n",
      "Epoch 81/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8326 - loss: 0.3665\n",
      "Epoch 82/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8504 - loss: 0.3516\n",
      "Epoch 83/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8525 - loss: 0.3425\n",
      "Epoch 84/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8463 - loss: 0.3617\n",
      "Epoch 85/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8439 - loss: 0.3535\n",
      "Epoch 86/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8530 - loss: 0.3390\n",
      "Epoch 87/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8515 - loss: 0.3454\n",
      "Epoch 88/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.3622\n",
      "Epoch 89/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8501 - loss: 0.3458\n",
      "Epoch 90/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8446 - loss: 0.3507\n",
      "Epoch 91/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8414 - loss: 0.3548\n",
      "Epoch 92/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8532 - loss: 0.3443\n",
      "Epoch 93/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8523 - loss: 0.3504\n",
      "Epoch 94/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8452 - loss: 0.3531\n",
      "Epoch 95/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8486 - loss: 0.3479\n",
      "Epoch 96/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8525 - loss: 0.3354\n",
      "Epoch 97/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8473 - loss: 0.3495\n",
      "Epoch 98/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8596 - loss: 0.3376\n",
      "Epoch 99/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8474 - loss: 0.3423\n",
      "Epoch 100/100\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8481 - loss: 0.3454\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8004 - loss: 0.4374 \n",
      "[0.4362846314907074, 0.797676682472229]\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.71      0.78      1033\n",
      "           1       0.76      0.88      0.81      1033\n",
      "\n",
      "    accuracy                           0.80      2066\n",
      "   macro avg       0.81      0.80      0.80      2066\n",
      "weighted avg       0.81      0.80      0.80      2066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_predicted_rounded_oversampling_SMOTE = ANN(X_train_oversampling_SMOTE, Y_train_oversampling_SMOTE, X_test_oversampling_SMOTE, Y_test_oversampling_SMOTE, 'binary_crossentropy', -1)\n",
    "\n",
    "\n",
    "# Insights: \n",
    "# 1) The results show that when imbalanced dataset is handled using SMOTE oversampling technique, the precision, recall and F1-score for Class 1 (minority class) samples are improved, but the precision, recall and F1-score for Class 0 (majority class) samples decreased, compared to the results obtained when imbalanced dataset is not handled. \n",
    "# But that's ok, because now you are doing fair treatment for minority class and majority class (the model now performs(predicts) equally well for samples of all classes)\n",
    "# 2) 259 batch for each epoch, because by default the batch size is 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 4: Use of Ensemble with undersampling\n",
    "\n",
    "Let's say in test set, number samples of Class 0 = j while number samples of Class 1 = k, where j>k & (j : k) = (3 : 1). We divide the majority class (Class 0) samples into 3 batches\n",
    "\n",
    "<img src=\"hidden\\ensemble.png\" alt=\"This image is a representation of the simple neural network\" style=\"width: 400px;\"/>  <br /><br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample statistics in dataset (overall):\n",
      "Churn\n",
      "0    5163\n",
      "1    1869\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Save the features of the dataset into X variable\n",
    "X = df2.drop('Churn', axis='columns')\n",
    "\n",
    "# Save the ground truth of the dataset into Y variable\n",
    "Y = df2['Churn']\n",
    "\n",
    "# The dataset is imbalance (Class 0 [Churn=0, not leaving] has 5163 samples; Class 1 [Churn=1, leaving] has 1869 samples)\n",
    "print('\\nSample statistics in dataset (overall):')\n",
    "print(Y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the features and ground truths variables into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversampled train set samples statistics:\n",
      " Churn\n",
      "0    4130\n",
      "1    1495\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Oversampled test set samples statistics:\n",
      " Churn\n",
      "0    1033\n",
      "1     374\n",
      "Name: count, dtype: int64\n",
      "\n",
      "he ratio of Class 0 : Class 1 in train set=  2.762541806020067\n"
     ]
    }
   ],
   "source": [
    "# stratify takes the ground truths variable as input to ensure the samples of different classes in train and test sets are balanced [class distribution is equal] (based on the ratio of the samples of different classes in ground truths variable)\n",
    "X_train_undersampling_ensemble, X_test_undersampling_ensemble, Y_train_undersampling_ensemble, Y_test_undersampling_ensemble = train_test_split(X, Y, test_size=0.2, random_state=15, stratify=Y)\n",
    "\n",
    "print('Oversampled train set samples statistics:\\n', Y_train_undersampling_ensemble.value_counts()) \n",
    "print('\\nOversampled test set samples statistics:\\n', Y_test_undersampling_ensemble.value_counts()) \n",
    "\n",
    "# The ratio of Class 0 : Class 1 in train set = 2.76 (approx. 3). So we divide the majority class (Class 0) samples in train set into 3 batches OR using a batch of size = Class 1 samples number in train set (because also close to 1378)\n",
    "print('\\nhe ratio of Class 0 : Class 1 in train set= ', Y_train_undersampling_ensemble.value_counts()[0]/Y_train_undersampling_ensemble.value_counts()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 of ensemble method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy X_train and save into a new dataframe called df3 (df3 dataframe only contains train set samples)\n",
    "df3 = X_train_undersampling_ensemble.copy()\n",
    "# Create a new column called Churn in df3, then store information of Y_train_undersampling_ensemble in that newly created column\n",
    "df3['Churn'] = Y_train_undersampling_ensemble\n",
    "\n",
    "# Divide by class\n",
    "# Save only Class 0 samples in df3 dataframe to a new dataframe called df3_class_0\n",
    "df3_class_0 = df3[df3['Churn']==0]\n",
    "# Save only Class 1 samples in df3 dataframe to a new dataframe called df3_class_1\n",
    "df3_class_1 = df3[df3['Churn']==1]\n",
    "\n",
    "# Self-define function to take a partition of majority class samples in train set, then concatenate them with minority class samples, then split all of them into features and ground truths variables\n",
    "def get_train_batch(df_majority, df_minority, start, end):\n",
    "    df_train_function = pd.concat([df_majority[start:end], df_minority], axis=0)\n",
    "\n",
    "    X_train_function = df_train_function.drop('Churn', axis='columns')\n",
    "    Y_train_function = df_train_function.Churn\n",
    "\n",
    "    return X_train_function, Y_train_function\n",
    "\n",
    "# Get the partition 1 of the majority class samples in train set\n",
    "X_train_function_partition1, Y_train_function_partition1  = get_train_batch(df3_class_0, df3_class_1, 0, 1495)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get prediction results over samples in function undersampled test set using ANN (trained with majority class samples of partition 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\weiyo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6368 - loss: 0.6530\n",
      "Epoch 2/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7561 - loss: 0.5305\n",
      "Epoch 3/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7455 - loss: 0.5160\n",
      "Epoch 4/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7539 - loss: 0.5034\n",
      "Epoch 5/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7663 - loss: 0.4931\n",
      "Epoch 6/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7744 - loss: 0.4828\n",
      "Epoch 7/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7711 - loss: 0.4832\n",
      "Epoch 8/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7760 - loss: 0.4748\n",
      "Epoch 9/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7809 - loss: 0.4630\n",
      "Epoch 10/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7675 - loss: 0.4816\n",
      "Epoch 11/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7680 - loss: 0.4757\n",
      "Epoch 12/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7746 - loss: 0.4696\n",
      "Epoch 13/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7734 - loss: 0.4758\n",
      "Epoch 14/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7733 - loss: 0.4722\n",
      "Epoch 15/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7786 - loss: 0.4729\n",
      "Epoch 16/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7841 - loss: 0.4607\n",
      "Epoch 17/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7798 - loss: 0.4590\n",
      "Epoch 18/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7711 - loss: 0.4802\n",
      "Epoch 19/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7744 - loss: 0.4729\n",
      "Epoch 20/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7734 - loss: 0.4719\n",
      "Epoch 21/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7900 - loss: 0.4530\n",
      "Epoch 22/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7883 - loss: 0.4567\n",
      "Epoch 23/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7873 - loss: 0.4549\n",
      "Epoch 24/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7835 - loss: 0.4694\n",
      "Epoch 25/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7872 - loss: 0.4577\n",
      "Epoch 26/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7855 - loss: 0.4648\n",
      "Epoch 27/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7897 - loss: 0.4624\n",
      "Epoch 28/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7857 - loss: 0.4513\n",
      "Epoch 29/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7874 - loss: 0.4637\n",
      "Epoch 30/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7959 - loss: 0.4478\n",
      "Epoch 31/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7827 - loss: 0.4616\n",
      "Epoch 32/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7950 - loss: 0.4480\n",
      "Epoch 33/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7907 - loss: 0.4475\n",
      "Epoch 34/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7973 - loss: 0.4486\n",
      "Epoch 35/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7939 - loss: 0.4466\n",
      "Epoch 36/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8059 - loss: 0.4335\n",
      "Epoch 37/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8031 - loss: 0.4403\n",
      "Epoch 38/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8033 - loss: 0.4289\n",
      "Epoch 39/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7938 - loss: 0.4415\n",
      "Epoch 40/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7934 - loss: 0.4526\n",
      "Epoch 41/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7925 - loss: 0.4527\n",
      "Epoch 42/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7970 - loss: 0.4430\n",
      "Epoch 43/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7835 - loss: 0.4493\n",
      "Epoch 44/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8060 - loss: 0.4289\n",
      "Epoch 45/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8031 - loss: 0.4374\n",
      "Epoch 46/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7882 - loss: 0.4566\n",
      "Epoch 47/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7975 - loss: 0.4439\n",
      "Epoch 48/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7929 - loss: 0.4441\n",
      "Epoch 49/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7958 - loss: 0.4347\n",
      "Epoch 50/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8008 - loss: 0.4387\n",
      "Epoch 51/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7896 - loss: 0.4479\n",
      "Epoch 52/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8045 - loss: 0.4258\n",
      "Epoch 53/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7991 - loss: 0.4310\n",
      "Epoch 54/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8145 - loss: 0.4175\n",
      "Epoch 55/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8035 - loss: 0.4330\n",
      "Epoch 56/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8003 - loss: 0.4255\n",
      "Epoch 57/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7930 - loss: 0.4372\n",
      "Epoch 58/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8051 - loss: 0.4244\n",
      "Epoch 59/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8083 - loss: 0.4135\n",
      "Epoch 60/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8138 - loss: 0.4247\n",
      "Epoch 61/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8059 - loss: 0.4369\n",
      "Epoch 62/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8165 - loss: 0.3997\n",
      "Epoch 63/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8075 - loss: 0.4200\n",
      "Epoch 64/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8022 - loss: 0.4233\n",
      "Epoch 65/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8070 - loss: 0.4243\n",
      "Epoch 66/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8034 - loss: 0.4320\n",
      "Epoch 67/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8006 - loss: 0.4184\n",
      "Epoch 68/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8057 - loss: 0.4232\n",
      "Epoch 69/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8034 - loss: 0.4233\n",
      "Epoch 70/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8067 - loss: 0.4248\n",
      "Epoch 71/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8170 - loss: 0.4077\n",
      "Epoch 72/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8036 - loss: 0.4162\n",
      "Epoch 73/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8115 - loss: 0.4135\n",
      "Epoch 74/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8077 - loss: 0.4138\n",
      "Epoch 75/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7981 - loss: 0.4217\n",
      "Epoch 76/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8080 - loss: 0.4187\n",
      "Epoch 77/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8127 - loss: 0.4157\n",
      "Epoch 78/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8230 - loss: 0.4105\n",
      "Epoch 79/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8028 - loss: 0.4181\n",
      "Epoch 80/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8077 - loss: 0.4114\n",
      "Epoch 81/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8047 - loss: 0.4252\n",
      "Epoch 82/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8154 - loss: 0.4135\n",
      "Epoch 83/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8218 - loss: 0.4083\n",
      "Epoch 84/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8075 - loss: 0.4114\n",
      "Epoch 85/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8093 - loss: 0.4138\n",
      "Epoch 86/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8096 - loss: 0.4118\n",
      "Epoch 87/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8122 - loss: 0.4092\n",
      "Epoch 88/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8187 - loss: 0.4037\n",
      "Epoch 89/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8148 - loss: 0.4046\n",
      "Epoch 90/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8233 - loss: 0.3908\n",
      "Epoch 91/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8201 - loss: 0.4080\n",
      "Epoch 92/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8101 - loss: 0.4005\n",
      "Epoch 93/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8151 - loss: 0.4069\n",
      "Epoch 94/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8081 - loss: 0.4139\n",
      "Epoch 95/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8204 - loss: 0.3969\n",
      "Epoch 96/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8161 - loss: 0.4020\n",
      "Epoch 97/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8269 - loss: 0.3905\n",
      "Epoch 98/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8199 - loss: 0.3993\n",
      "Epoch 99/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8147 - loss: 0.3976\n",
      "Epoch 100/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8124 - loss: 0.4105\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7215 - loss: 0.5885  \n",
      "[0.6056077480316162, 0.7022032737731934]\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.66      0.77      1033\n",
      "           1       0.47      0.81      0.59       374\n",
      "\n",
      "    accuracy                           0.70      1407\n",
      "   macro avg       0.69      0.74      0.68      1407\n",
      "weighted avg       0.79      0.70      0.72      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using model 1 of the ensemble method\n",
    "Y_predicted_rounded_ensemble_partition1 = ANN(X_train_function_partition1, Y_train_function_partition1, X_test_undersampling_ensemble, Y_test_undersampling_ensemble, 'binary_crossentropy', -1)\n",
    "\n",
    "# Insights: Ignore the classification report of this model (we only look at the classification report of the majority vote part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 of ensemble method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the partition 2 of the majority class samples in train set\n",
    "X_train_function_partition2, Y_train_function_partition2  = get_train_batch(df3_class_0, df3_class_1, 1495, 2*(1495))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get prediction results over samples in function undersampled test set using ANN (trained with majority class samples of partition 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\weiyo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6514 - loss: 0.6427\n",
      "Epoch 2/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7457 - loss: 0.5238\n",
      "Epoch 3/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7624 - loss: 0.4880\n",
      "Epoch 4/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7572 - loss: 0.4930\n",
      "Epoch 5/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7669 - loss: 0.4812\n",
      "Epoch 6/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7648 - loss: 0.4861\n",
      "Epoch 7/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7727 - loss: 0.4692\n",
      "Epoch 8/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7646 - loss: 0.4759\n",
      "Epoch 9/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7706 - loss: 0.4716\n",
      "Epoch 10/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7678 - loss: 0.4667\n",
      "Epoch 11/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7726 - loss: 0.4610\n",
      "Epoch 12/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7653 - loss: 0.4682\n",
      "Epoch 13/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7559 - loss: 0.4892\n",
      "Epoch 14/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7717 - loss: 0.4607\n",
      "Epoch 15/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7653 - loss: 0.4751\n",
      "Epoch 16/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7890 - loss: 0.4500\n",
      "Epoch 17/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7748 - loss: 0.4622\n",
      "Epoch 18/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7733 - loss: 0.4567\n",
      "Epoch 19/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7732 - loss: 0.4617\n",
      "Epoch 20/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7721 - loss: 0.4630\n",
      "Epoch 21/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7629 - loss: 0.4711\n",
      "Epoch 22/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7706 - loss: 0.4575\n",
      "Epoch 23/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7806 - loss: 0.4502\n",
      "Epoch 24/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7710 - loss: 0.4681\n",
      "Epoch 25/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7753 - loss: 0.4604\n",
      "Epoch 26/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7821 - loss: 0.4451\n",
      "Epoch 27/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7750 - loss: 0.4474\n",
      "Epoch 28/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7803 - loss: 0.4460\n",
      "Epoch 29/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7843 - loss: 0.4426\n",
      "Epoch 30/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7854 - loss: 0.4324\n",
      "Epoch 31/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7657 - loss: 0.4614\n",
      "Epoch 32/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8008 - loss: 0.4214\n",
      "Epoch 33/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7735 - loss: 0.4508\n",
      "Epoch 34/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8028 - loss: 0.4303\n",
      "Epoch 35/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7939 - loss: 0.4295\n",
      "Epoch 36/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7935 - loss: 0.4294\n",
      "Epoch 37/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7892 - loss: 0.4293\n",
      "Epoch 38/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7853 - loss: 0.4357\n",
      "Epoch 39/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7879 - loss: 0.4361\n",
      "Epoch 40/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8033 - loss: 0.4200\n",
      "Epoch 41/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7873 - loss: 0.4359\n",
      "Epoch 42/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8056 - loss: 0.4189\n",
      "Epoch 43/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7865 - loss: 0.4307\n",
      "Epoch 44/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8052 - loss: 0.4222\n",
      "Epoch 45/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7944 - loss: 0.4231\n",
      "Epoch 46/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7975 - loss: 0.4146\n",
      "Epoch 47/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7890 - loss: 0.4256\n",
      "Epoch 48/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7831 - loss: 0.4316\n",
      "Epoch 49/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7882 - loss: 0.4469\n",
      "Epoch 50/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8048 - loss: 0.4123\n",
      "Epoch 51/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7941 - loss: 0.4184\n",
      "Epoch 52/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7994 - loss: 0.4115\n",
      "Epoch 53/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8073 - loss: 0.4115\n",
      "Epoch 54/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8076 - loss: 0.4174\n",
      "Epoch 55/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8008 - loss: 0.4203\n",
      "Epoch 56/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8193 - loss: 0.3968\n",
      "Epoch 57/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7972 - loss: 0.4196\n",
      "Epoch 58/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8042 - loss: 0.4230\n",
      "Epoch 59/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7934 - loss: 0.4143\n",
      "Epoch 60/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8023 - loss: 0.4133\n",
      "Epoch 61/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8020 - loss: 0.4141\n",
      "Epoch 62/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8020 - loss: 0.4158\n",
      "Epoch 63/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7946 - loss: 0.4245\n",
      "Epoch 64/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8027 - loss: 0.4126\n",
      "Epoch 65/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8001 - loss: 0.4044\n",
      "Epoch 66/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8045 - loss: 0.4080\n",
      "Epoch 67/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8099 - loss: 0.4021\n",
      "Epoch 68/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8121 - loss: 0.4021\n",
      "Epoch 69/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8081 - loss: 0.3992\n",
      "Epoch 70/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8069 - loss: 0.4108\n",
      "Epoch 71/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8108 - loss: 0.4030\n",
      "Epoch 72/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8051 - loss: 0.4129\n",
      "Epoch 73/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8013 - loss: 0.4083\n",
      "Epoch 74/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8203 - loss: 0.3888\n",
      "Epoch 75/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8039 - loss: 0.4059\n",
      "Epoch 76/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8127 - loss: 0.3934\n",
      "Epoch 77/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8262 - loss: 0.3815\n",
      "Epoch 78/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8063 - loss: 0.4011\n",
      "Epoch 79/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7946 - loss: 0.4260\n",
      "Epoch 80/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8147 - loss: 0.3888\n",
      "Epoch 81/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8060 - loss: 0.4132\n",
      "Epoch 82/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8093 - loss: 0.3939\n",
      "Epoch 83/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8049 - loss: 0.4081\n",
      "Epoch 84/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8055 - loss: 0.3928\n",
      "Epoch 85/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8120 - loss: 0.3976\n",
      "Epoch 86/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8191 - loss: 0.3884\n",
      "Epoch 87/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8125 - loss: 0.3925\n",
      "Epoch 88/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8206 - loss: 0.3822\n",
      "Epoch 89/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8192 - loss: 0.3890\n",
      "Epoch 90/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8119 - loss: 0.3978\n",
      "Epoch 91/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8084 - loss: 0.3955\n",
      "Epoch 92/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8156 - loss: 0.4021\n",
      "Epoch 93/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8169 - loss: 0.3946\n",
      "Epoch 94/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8147 - loss: 0.3963\n",
      "Epoch 95/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8109 - loss: 0.3945\n",
      "Epoch 96/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8111 - loss: 0.3916\n",
      "Epoch 97/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8192 - loss: 0.3975\n",
      "Epoch 98/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8113 - loss: 0.3965\n",
      "Epoch 99/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8210 - loss: 0.3897\n",
      "Epoch 100/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8306 - loss: 0.3689\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7376 - loss: 0.5678\n",
      "[0.6000884175300598, 0.711442768573761]\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.70      0.78      1033\n",
      "           1       0.47      0.74      0.58       374\n",
      "\n",
      "    accuracy                           0.71      1407\n",
      "   macro avg       0.68      0.72      0.68      1407\n",
      "weighted avg       0.77      0.71      0.73      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using model 2 of the ensemble method\n",
    "Y_predicted_rounded_ensemble_partition2 = ANN(X_train_function_partition2, Y_train_function_partition2, X_test_undersampling_ensemble, Y_test_undersampling_ensemble, 'binary_crossentropy', -1)\n",
    "\n",
    "# Insights: Ignore the classification report of this model (we only look at the classification report of the majority vote part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 of ensemble method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the partition 3 of the majority class samples in train set\n",
    "X_train_function_partition3, Y_train_function_partition3  = get_train_batch(df3_class_0, df3_class_1, 2*1495, 3*1495)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get prediction results over samples in function undersampled test set using ANN (trained with majority class samples of partition 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\weiyo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5854 - loss: 0.6850\n",
      "Epoch 2/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7606 - loss: 0.5554\n",
      "Epoch 3/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7490 - loss: 0.5117\n",
      "Epoch 4/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7732 - loss: 0.4802\n",
      "Epoch 5/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7609 - loss: 0.4996\n",
      "Epoch 6/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7781 - loss: 0.4762\n",
      "Epoch 7/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7757 - loss: 0.4692\n",
      "Epoch 8/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7722 - loss: 0.4733\n",
      "Epoch 9/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7776 - loss: 0.4668\n",
      "Epoch 10/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7934 - loss: 0.4444\n",
      "Epoch 11/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7828 - loss: 0.4660\n",
      "Epoch 12/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7777 - loss: 0.4786\n",
      "Epoch 13/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7775 - loss: 0.4621\n",
      "Epoch 14/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7905 - loss: 0.4466\n",
      "Epoch 15/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7923 - loss: 0.4514\n",
      "Epoch 16/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7884 - loss: 0.4494\n",
      "Epoch 17/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7992 - loss: 0.4499\n",
      "Epoch 18/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7829 - loss: 0.4633\n",
      "Epoch 19/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7832 - loss: 0.4484\n",
      "Epoch 20/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7956 - loss: 0.4374\n",
      "Epoch 21/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7966 - loss: 0.4336\n",
      "Epoch 22/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7883 - loss: 0.4525\n",
      "Epoch 23/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8103 - loss: 0.4364\n",
      "Epoch 24/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7962 - loss: 0.4376\n",
      "Epoch 25/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7827 - loss: 0.4456\n",
      "Epoch 26/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7878 - loss: 0.4463\n",
      "Epoch 27/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8086 - loss: 0.4317\n",
      "Epoch 28/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7995 - loss: 0.4440\n",
      "Epoch 29/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7901 - loss: 0.4403\n",
      "Epoch 30/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7980 - loss: 0.4264\n",
      "Epoch 31/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7966 - loss: 0.4368\n",
      "Epoch 32/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8056 - loss: 0.4291\n",
      "Epoch 33/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8088 - loss: 0.4301\n",
      "Epoch 34/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8010 - loss: 0.4319\n",
      "Epoch 35/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7974 - loss: 0.4401\n",
      "Epoch 36/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7903 - loss: 0.4547\n",
      "Epoch 37/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8071 - loss: 0.4312\n",
      "Epoch 38/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8044 - loss: 0.4311\n",
      "Epoch 39/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8115 - loss: 0.4248\n",
      "Epoch 40/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8074 - loss: 0.4198\n",
      "Epoch 41/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7936 - loss: 0.4384\n",
      "Epoch 42/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8135 - loss: 0.4162\n",
      "Epoch 43/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8103 - loss: 0.4268\n",
      "Epoch 44/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8047 - loss: 0.4310\n",
      "Epoch 45/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8164 - loss: 0.4134\n",
      "Epoch 46/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8175 - loss: 0.4109\n",
      "Epoch 47/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8168 - loss: 0.4201\n",
      "Epoch 48/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8088 - loss: 0.4121\n",
      "Epoch 49/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8148 - loss: 0.4214\n",
      "Epoch 50/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8143 - loss: 0.4113\n",
      "Epoch 51/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8057 - loss: 0.4241\n",
      "Epoch 52/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8085 - loss: 0.4186\n",
      "Epoch 53/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8130 - loss: 0.4129\n",
      "Epoch 54/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8088 - loss: 0.4264\n",
      "Epoch 55/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8161 - loss: 0.4000\n",
      "Epoch 56/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8064 - loss: 0.4215\n",
      "Epoch 57/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8158 - loss: 0.4164\n",
      "Epoch 58/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8137 - loss: 0.4000\n",
      "Epoch 59/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8184 - loss: 0.4020\n",
      "Epoch 60/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8112 - loss: 0.4068\n",
      "Epoch 61/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8224 - loss: 0.4048\n",
      "Epoch 62/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8129 - loss: 0.4148\n",
      "Epoch 63/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8284 - loss: 0.3846\n",
      "Epoch 64/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8161 - loss: 0.4047\n",
      "Epoch 65/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8206 - loss: 0.3934\n",
      "Epoch 66/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8149 - loss: 0.4096\n",
      "Epoch 67/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8290 - loss: 0.3807\n",
      "Epoch 68/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8192 - loss: 0.3968\n",
      "Epoch 69/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8101 - loss: 0.4145\n",
      "Epoch 70/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8085 - loss: 0.4090\n",
      "Epoch 71/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8111 - loss: 0.4136\n",
      "Epoch 72/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8159 - loss: 0.3935\n",
      "Epoch 73/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8143 - loss: 0.4079\n",
      "Epoch 74/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8196 - loss: 0.4013\n",
      "Epoch 75/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8162 - loss: 0.3917\n",
      "Epoch 76/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8293 - loss: 0.3877\n",
      "Epoch 77/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8239 - loss: 0.3867\n",
      "Epoch 78/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8193 - loss: 0.3874\n",
      "Epoch 79/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8242 - loss: 0.3985\n",
      "Epoch 80/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8198 - loss: 0.4033\n",
      "Epoch 81/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8242 - loss: 0.3990\n",
      "Epoch 82/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8233 - loss: 0.4015\n",
      "Epoch 83/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8092 - loss: 0.4140\n",
      "Epoch 84/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8291 - loss: 0.3907\n",
      "Epoch 85/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8355 - loss: 0.3864\n",
      "Epoch 86/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8223 - loss: 0.3926\n",
      "Epoch 87/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8246 - loss: 0.3831\n",
      "Epoch 88/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8365 - loss: 0.3755\n",
      "Epoch 89/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8157 - loss: 0.3935\n",
      "Epoch 90/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8329 - loss: 0.3815\n",
      "Epoch 91/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8290 - loss: 0.3883\n",
      "Epoch 92/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8281 - loss: 0.3817\n",
      "Epoch 93/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8341 - loss: 0.3797\n",
      "Epoch 94/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8288 - loss: 0.3854\n",
      "Epoch 95/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8250 - loss: 0.3868\n",
      "Epoch 96/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8372 - loss: 0.3810\n",
      "Epoch 97/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8224 - loss: 0.3793\n",
      "Epoch 98/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8351 - loss: 0.3791\n",
      "Epoch 99/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8190 - loss: 0.3860\n",
      "Epoch 100/100\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8194 - loss: 0.3871\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - accuracy: 0.6873 - loss: 0.6197\n",
      "[0.6386092305183411, 0.6652451753616333]\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.61      0.73      1033\n",
      "           1       0.43      0.81      0.56       374\n",
      "\n",
      "    accuracy                           0.67      1407\n",
      "   macro avg       0.66      0.71      0.65      1407\n",
      "weighted avg       0.77      0.67      0.68      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using model 3 of the ensemble method\n",
    "Y_predicted_rounded_ensemble_partition3 = ANN(X_train_function_partition3, Y_train_function_partition3, X_test_undersampling_ensemble, Y_test_undersampling_ensemble, 'binary_crossentropy', -1)\n",
    "\n",
    "# Insights: Ignore the classification report of this model (we only look at the classification report of the majority vote part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take majority vote of the ensemble method (majority vote among the 3 models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.66      0.76      1033\n",
      "           1       0.46      0.80      0.58       374\n",
      "\n",
      "    accuracy                           0.69      1407\n",
      "   macro avg       0.68      0.73      0.67      1407\n",
      "weighted avg       0.78      0.69      0.71      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a numpy array called Y_predicted_rounded_ensemble_majority, by simply copy the information of Y_predicted_rounded_ensemble_partition1 numpy array to it\n",
    "Y_predicted_rounded_ensemble_majority = Y_predicted_rounded_ensemble_partition1.copy()\n",
    "\n",
    "# Run this for loop for len(Y_predicted_rounded_ensemble_partition1) iterations\n",
    "for i in range(len(Y_predicted_rounded_ensemble_partition1)):\n",
    "    # At each iteration, access a predicted result made by model 1, model 2, and model 3 respectively, then save the sum of the predicted results of all models for a sample to n_ones variable at an index. At ith iteration, the predicted result made by each model is for the ith sample in the Y_test_undersampling_ensemble, the sum of the predicted results will be saved at ith index of n_ones.\n",
    "    n_ones = Y_predicted_rounded_ensemble_partition1[i] + Y_predicted_rounded_ensemble_partition2[i] + Y_predicted_rounded_ensemble_partition3[i]\n",
    "    if n_ones>1: # Since each model will provide predicted result only either 0 or 1 for a sample. If n_ones at an index >1, means at least 2 models provide predicted result of 1, so the majority vote is 1 (means the ensemble method provide predicted result of 1) for the corresponding sample in test set. \n",
    "        Y_predicted_rounded_ensemble_majority[i] = 1\n",
    "    else:  # If n_ones at an index = 0, means all 3 models provide predicted result of 0, so the majority vote is 0 (means the ensemble method provide predicted result of 0) for the corresponding sample in test set. \n",
    "        Y_predicted_rounded_ensemble_majority[i] = 0\n",
    "\n",
    "# Print the classification report of the ensemble method\n",
    "print(classification_report(Y_test_undersampling_ensemble, Y_predicted_rounded_ensemble_majority))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
